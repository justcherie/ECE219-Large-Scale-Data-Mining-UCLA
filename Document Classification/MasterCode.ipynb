{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "# Data Mining\n",
    "\n",
    "---------------------------------------------------------\n",
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Collect training data from 20 Newsgroups data set, and plot a histogram of each label's occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib.colors as pltc\n",
    "from itertools import cycle\n",
    "import numpy as np \n",
    "np.random.seed(42) \n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category labels present in the data set are:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
     ]
    }
   ],
   "source": [
    "twenty_train_dataset = fetch_20newsgroups(subset=\"train\",\n",
    "                                      shuffle=True,\n",
    "                                      random_state=42)\n",
    "twenty_test_dataset  = fetch_20newsgroups(subset=\"test\",\n",
    "                                     shuffle=True,\n",
    "                                     random_state=42)\n",
    "# bad choice of variable name.\n",
    "cat_labels = np.unique(twenty_train_dataset.target)\n",
    "print('Category labels present in the data set are: ', cat_labels)\n",
    "num_classes = len(np.unique(twenty_train_dataset.target))\n",
    "[freq_classes, _] = np.histogram(twenty_train_dataset.target,\n",
    "                                 bins=np.arange(0,num_classes+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cycl = cycle('bgrcmky')\n",
    "for i in range(len(cat_labels)):\n",
    "    plt.bar([cat_labels[i]], [freq_classes[i]], width=0.25,\n",
    "           align='center', color=next(cycl),\n",
    "           alpha=0.5, label=twenty_train_dataset.target_names[i])\n",
    "plt.xticks(cat_labels, twenty_train_dataset.target_names, rotation=90)\n",
    "# plt.legend()\n",
    "plt.ylabel('Number of documents')\n",
    "plt.subplots_adjust(bottom= 0.22, top = 0.95)\n",
    "plt.title(\"Number of documents in each category\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the bar plot it appears the dataset is quite balanced except for religion, politcal misc categories. Let us quanify this by using entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate:  0.9981706679371282\n"
     ]
    }
   ],
   "source": [
    "classes, count_classes = np.unique(twenty_train_dataset.target, return_counts=True)\n",
    "n = len(twenty_train_dataset.target)\n",
    "entropy = 0\n",
    "for count in count_classes:\n",
    "    entropy += -(count/n)*np.log(count/n)\n",
    "estimate = entropy/np.log(len(classes))\n",
    "print('estimate: ', estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closer the estimate is to 1 the better balanced is our dataset. We got 0.998 which is very high so our data set is quite balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 4 categories are computer related (we will call this class 0) and the second 4 are recreation related (we will call this class 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "#### The first and most important step in any Machine learning or Data Mining task is data extraction, data cleaning\n",
    "\n",
    "#### The following tasks are performed as a part of Data Cleaning exercise.\n",
    "\n",
    "* Remove words with frequency less than 3.\n",
    "<br />\n",
    "* Remove Stop words using the default CountVectorizer functions stop words (As specified in question)\n",
    "<br />\n",
    "* Perform Lemmatization using Wordnet's lemmatizer.\n",
    "\n",
    "#### Feature Extraction \n",
    "\n",
    "* Formed the bag of words representation for our corpus.\n",
    "* Normalized the frequency of each term based on importance (Term Frequency Inverse Document Frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data after lemmatization but before TF-IDF:  (4732, 16600)\n",
      "Size of testing data after lemmatization but before TF-IDF:   (3150, 16600)\n",
      "Shape of train TF-IDF matrix:  (4732, 16600)\n",
      "Shape of test TF-IDF matrix:   (3150, 16600)\n"
     ]
    }
   ],
   "source": [
    "#Q2: Extract features w/ particular specifications\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from pickle import dump\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "\n",
    "comp_categories = [ 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', \n",
    "                   'comp.sys.mac.hardware']\n",
    "rec_categories = ['rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "train_dataset = fetch_20newsgroups(subset='train', categories=comp_categories+rec_categories, \n",
    "                                  shuffle=True, random_state=42,)\n",
    "test_dataset = fetch_20newsgroups(subset='test', categories=comp_categories+rec_categories, \n",
    "                                 shuffle=True, random_state=42,)\n",
    "counts = []\n",
    "\n",
    "wnl = nltk.wordnet.WordNetLemmatizer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "                  'VB':'v', 'RB':'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n'\n",
    "\n",
    "def lemmatize_sent(list_word):\n",
    "    # Text input is string, returns array of lowercased strings(words).\n",
    "    return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) \n",
    "            for word, tag in pos_tag(list_word)]\n",
    "\n",
    "#NOTE: The following code was developed to remove all numbers (including floats like 6.7)\n",
    "#      as isdigit doesn't work on floats. However, the floats it removed were:\n",
    "#      ['35002_4401', '5e8', '5e9', '6e1', '9_6', 'inf', 'infinity']\n",
    "#      So we decided not to use it\n",
    "#def is_number(s):\n",
    "#    try:\n",
    "#        float(s)\n",
    "#        return True\n",
    "#    except:\n",
    "#        return False\n",
    "\n",
    "def rmv_nums(doc):\n",
    "    #gets rid of numbers including floats\n",
    "    #does lemmatization with nltk.wordnet.WordNetLemmatizer and pos_tag\n",
    "    return (word for word in lemmatize_sent(analyzer(doc)) \n",
    "            if not word.isdigit())\n",
    "\n",
    "\n",
    "#CountVectorizer returns a callable that handles preprocessing and tokenization\n",
    "#Use the “english” stopwords of the CountVectorizer\n",
    "vectorizer=CountVectorizer(analyzer=rmv_nums,min_df=3,stop_words='english')\n",
    "\n",
    "#do feature extraction (train):\n",
    "X_train_counts=vectorizer.fit_transform(train_dataset.data) #get matrix of doc-term counts (training data)\n",
    "print('Size of training data after lemmatization but before TF-IDF: ', X_train_counts.shape) #4732 docs, 16292 terms (originally 4732 docs, 79218 terms)\n",
    "X_test_counts=vectorizer.transform(test_dataset.data) \n",
    "print('Size of testing data after lemmatization but before TF-IDF:  ', X_test_counts.shape) #3150 docs, 16292 terms (originally 3150 docs, 79218 terms)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print('Shape of train TF-IDF matrix: ',X_train_tfidf.shape)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "print('Shape of test TF-IDF matrix:  ',X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the shape of the category count matrices for the train and test data set are 4732x16600 and 3150x16600 respectively.\n",
    "In addition, the shape doesn't change once the TF-IDF transform is applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To escape from the Curse of Dimensionality we perform Dimensionality reduction.<br />\n",
    "* We have used 2 Dimensionality reduction techniques <br />\n",
    "    1) Latent Semantic Analysis <br />\n",
    "    2) Non-Negative Matrix Factorization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do dimensionality reduction with LSA/LSI. In this part of code, I created the SVD object and transform the test date into a reduced version of itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD reduced training set shape:  (4732, 50)\n",
      "SVD reduced testing set shape:   (3150, 50)\n"
     ]
    }
   ],
   "source": [
    "#Q3\n",
    "#LSA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "X_train_LSA = svd.fit_transform(X_train_tfidf)\n",
    "X_test_LSA = svd.transform(X_test_tfidf)\n",
    "print('SVD reduced training set shape: ', X_train_LSA.shape)\n",
    "print('SVD reduced testing set shape:  ', X_test_LSA.shape)\n",
    "\n",
    "V = svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from LSA training set:  3895.4186796933277\n",
      "Error from LSA testing set:   2676.4912327221027\n"
     ]
    }
   ],
   "source": [
    "LSA_train_error=np.sum(np.array(X_train_tfidf - X_train_LSA.dot(V))**2)\n",
    "LSA_test_error=np.sum(np.array(X_test_tfidf - X_test_LSA.dot(V))**2)\n",
    "\n",
    "print('Error from LSA training set: ', LSA_train_error)\n",
    "print('Error from LSA testing set:  ', LSA_test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non Negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do dimensionality reduction with NMF. Make the NMF object, which find a W and H, and then uses H to transform the test data too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF reduced (W) training set shape:  (4732, 50)\n",
      "NMF reduced (W) testing set shape:   (3150, 50)\n",
      "NMF reduced (H) set shape:           (50, 16600)\n"
     ]
    }
   ],
   "source": [
    "#Q3 cont\n",
    "#NMF\n",
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=50, init='random', random_state=42)\n",
    "\n",
    "W_train = nmf.fit_transform(X_train_tfidf) #Find our W and H from the train data\n",
    "W_test  = nmf.transform(X_test_tfidf) #apply the found H and do the minimization\n",
    "\n",
    "H = nmf.components_\n",
    "\n",
    "print('NMF reduced (W) training set shape: ', W_train.shape)\n",
    "print('NMF reduced (W) testing set shape:  ', W_test.shape)\n",
    "print('NMF reduced (H) set shape:          ', H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from NMF training set:  3940.342513932875\n",
      "Error from NMF testing set:   2689.0690267386613\n"
     ]
    }
   ],
   "source": [
    "#Get NMF error\n",
    "NMF_train_error = np.sum(np.array(X_train_tfidf - W_train.dot(H))**2)\n",
    "NMF_test_error = np.sum(np.array(X_test_tfidf - W_test.dot(H))**2)\n",
    "\n",
    "print('Error from NMF training set: ', NMF_train_error)\n",
    "print('Error from NMF testing set:  ', NMF_test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both NMF and LSA considers linear combination of 50 base vectors to represent the data but in case of NMF it takes postive linear combination to get more interpretable results (Partly NMF is inspired from the way our brain works). So NMF gives slightly more Error compared to LSA as NMF considers postive coefficients only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Classification Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "y_train = train_dataset.target > 3\n",
    "y_train = y_train.astype(int)\n",
    "y_test = test_dataset.target > 3\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "#hard\n",
    "clf_hard = LinearSVC(C=1000, random_state=42).fit(X_train_LSA, y_train)\n",
    "y_pred_hard = clf_hard.predict(X_test_LSA)\n",
    "scores_hard = clf_hard.decision_function(X_test_LSA)\n",
    "\n",
    "#soft\n",
    "clf_soft = LinearSVC(C=0.0001, random_state=42).fit(X_train_LSA, y_train)\n",
    "y_pred_soft = clf_soft.predict(X_test_LSA)\n",
    "scores_soft = clf_soft.decision_function(X_test_LSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area under hard svm curve 0.9956712626995645\n",
      "area under soft svm curve 0.968452668924367\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve:\n",
    "fpr_hard, tpr_hard, thresholds_hard = roc_curve(y_test, scores_hard)\n",
    "fpr_soft, tpr_soft, thresholds_soft = roc_curve(y_test, scores_soft)\n",
    "\n",
    "# area under the curve:\n",
    "roc_auc_hard = auc(fpr_hard,tpr_hard)\n",
    "roc_auc_soft = auc(fpr_soft,tpr_soft)\n",
    "print(\"area under hard svm curve\", roc_auc_hard)\n",
    "print(\"area under soft svm curve\", roc_auc_soft)\n",
    "\n",
    "# plot roc curves:\n",
    "\n",
    "plt.plot(fpr_soft, tpr_soft, 'r', label='soft margin svm')\n",
    "plt.plot(fpr_hard, tpr_hard, label='hard margin svm')\n",
    "plt.legend()\n",
    "plt.title('Hard and Soft Margin Linear SVM')\n",
    "plt.xlabel('false postive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observation: As we want the area under the ROC curve to be high, Hard margin SVM is a better choice in this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_hard = confusion_matrix(y_test, y_pred_hard)\n",
    "confusion_soft = confusion_matrix(y_test, y_pred_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix plot\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, title, cmap = plt.cm.Blues):\n",
    "    ctgrs = ['Class I \\n Computers','Class II \\n Recreation']\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title + ', without normalization')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(ctgrs))\n",
    "    plt.xticks(tick_marks, ctgrs, rotation=45)\n",
    "    plt.yticks(tick_marks, ctgrs)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot non-normalized confusion matrices\n",
    "plot_confusion_matrix(confusion_soft, title='Soft confusion matrix')\n",
    "plot_confusion_matrix(confusion_hard, title='Hard confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy, Recall, Precision and F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard accuracy:   0.9641269841269842     Soft accuracy:   0.6126984126984127\n",
      "Hard recall:     0.9855345911949686      Soft recall:     1.0\n",
      "Hard precision:  0.9456849728424864     Soft precision:  0.5658362989323843\n",
      "Hard F1 score:   0.9651986449029875     Soft F1 score:   0.7227272727272728\n"
     ]
    }
   ],
   "source": [
    "#hard\n",
    "accuracy_hard  = accuracy_score(y_test, y_pred_hard)\n",
    "recall_hard    = recall_score(y_test, y_pred_hard)\n",
    "precision_hard = precision_score(y_test, y_pred_hard)\n",
    "f1_score_hard  = f1_score(y_test, y_pred_hard)\n",
    "\n",
    "#soft\n",
    "accuracy_soft = accuracy_score(y_test, y_pred_soft)\n",
    "recall_soft = recall_score(y_test, y_pred_soft)\n",
    "precision_soft = precision_score(y_test, y_pred_soft)\n",
    "f1_score_soft = f1_score(y_test, y_pred_soft)\n",
    "\n",
    "print('Hard accuracy:  ', accuracy_hard,  '    Soft accuracy:  ', accuracy_soft)\n",
    "print('Hard recall:    ', recall_hard,    '     Soft recall:    ', recall_soft)\n",
    "print('Hard precision: ', precision_hard, '    Soft precision: ', precision_soft)\n",
    "print('Hard F1 score:  ', f1_score_hard,  '    Soft F1 score:  ', f1_score_soft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clearly we can see from the ROC curve and Confusion matrix Hard Margin SVM is better than Soft margin SVM.\n",
    "\n",
    "The reason why Soft margin SVM performed very badly is as follows:\n",
    "\n",
    "1) When we decrease the gamma parameter we allow classification errors to take place while decreasing the objective function that is norm of weight vector (try to increase the margin)\n",
    "\n",
    "2) When we kept the gamma to be very low, the classifier made a lot of errors (gamma very low so no penality) while decreasing the objective function that is norm of weight vector (try to increase the margin).\n",
    "\n",
    "So at gamma at 0.001 we got very poor accuracy. So gamma has to be tuned shouldn't be too less or high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores_k = []\n",
    "for k in range(-3,4):\n",
    "    clf_svm = LinearSVC(C=10**k).fit(X_train_LSA, y_train)\n",
    "    scores = cross_val_score(clf_svm, X_train_LSA, y_train, cv=5, scoring='accuracy')\n",
    "    scores_k.append(np.mean(scores))\n",
    "k_opt = 10**(np.argmax(scores_k)-3)\n",
    "print(k_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal Value of C is 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm_opt = LinearSVC(C=k_opt, random_state=42).fit(X_train_LSA, y_train)\n",
    "y_pred_svm_opt = clf_svm_opt.predict(X_test_LSA)\n",
    "scores_svm_opt = clf_svm_opt.decision_function(X_test_LSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve:\n",
    "fpr_opt, tpr_opt, thresholds_opt = roc_curve(y_test, scores_svm_opt)\n",
    "# plot roc curves:\n",
    "plt.plot(fpr_soft, tpr_soft, label='svm')\n",
    "plt.title('Optimal Linear SVM')\n",
    "plt.xlabel('false postive rate')\n",
    "plt.ylabel('true postive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot non-normalized confusion matrices\n",
    "confusion_opt = confusion_matrix(y_test, y_pred_svm_opt)\n",
    "plot_confusion_matrix(confusion_opt, title='Optimal SVM confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal SVM accuracy:   0.9707936507936508\n",
      "Optimal SVM recall:     0.980503144654088\n",
      "Optimal SVM precision:  0.9623456790123457\n",
      "Optimal SVM F1 score:   0.9713395638629283\n"
     ]
    }
   ],
   "source": [
    "accuracy_opt = accuracy_score(y_test, y_pred_svm_opt)\n",
    "recall_opt = recall_score(y_test, y_pred_svm_opt)\n",
    "precision_opt = precision_score(y_test, y_pred_svm_opt)\n",
    "f1_score_opt = f1_score(y_test, y_pred_svm_opt)\n",
    "\n",
    "print('Optimal SVM accuracy:  ', accuracy_opt)\n",
    "print('Optimal SVM recall:    ', recall_opt)\n",
    "print('Optimal SVM precision: ', precision_opt)\n",
    "print('Optimal SVM F1 score:  ', f1_score_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy increased from 96.4% to 97.07% by using Optimal Threshold (C is 10) SVM instead of Hard threshold SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [1 1 1 0 0 1 1 0 0 1]\n",
      "actual:     [1 1 1 0 0 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "#Combined code from Eden and Sarat\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# C very high value to simulate no regularization\n",
    "clf = LogisticRegression(C=1e10, random_state=42)\n",
    "clf.fit(X_train_LSA, y_train)\n",
    "y_pred = clf.predict(X_test_LSA)\n",
    "unrg_scores_prob = clf.predict_proba(X_test_LSA)[:, 1]\n",
    "\n",
    "\n",
    "predicted = y_pred[20:30]\n",
    "print('predicted: ', predicted)\n",
    "print('actual:    ', y_test[20:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area under losgitc regression curve 0.9958655861957749\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve:\n",
    "fpr, tpr, thresholds = roc_curve(\n",
    "    y_test, unrg_scores_prob)\n",
    "\n",
    "# area under the curve:\n",
    "roc_auc = auc(fpr,tpr)\n",
    "print(\"area under losgitc regression curve\", roc_auc)\n",
    "\n",
    "# plot roc curves:\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('Logistic Regression')\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy logistic:   0.9714285714285714\n",
      "Recall logistic:     0.9792452830188679\n",
      "Precision logistic:  0.9646840148698885\n",
      "F1 score logistic:   0.9719101123595505\n"
     ]
    }
   ],
   "source": [
    "#defining logitistic types\n",
    "unreg_confusion = confusion_matrix(y_test, y_pred)\n",
    "unreg_accuracy = accuracy_score(y_test, y_pred)\n",
    "unreg_recall = recall_score(y_test, y_pred)\n",
    "unreg_precision = precision_score(y_test, y_pred)\n",
    "unreg_f1_score = f1_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy logistic:  ', unreg_accuracy) #\n",
    "print('Recall logistic:    ', unreg_recall) #\n",
    "print('Precision logistic: ', unreg_precision) #\n",
    "print('F1 score logistic:  ', unreg_f1_score) #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers with Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal k-value for L1:  1.0\n",
      "Optimal C-value:  10.0\n",
      "This corresponds to an optimal regularization strength for L1 (inverse of C=10^k):  0.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from math import log\n",
    "\n",
    "C_pot = [0.001, 0.01, 0.1, 1, 10, 100, 1000] #potential regularization strengths for k=[-3,3] \n",
    "clf_l1 = LogisticRegressionCV(Cs=C_pot, cv=5, penalty='l1', refit=True,\n",
    "                                       solver='liblinear', random_state=42)\n",
    "clf_l1_test_score = []\n",
    "clf_l1.fit(X_train_LSA, y_train)\n",
    "for C_pot1 in C_pot:\n",
    "    clf_l1_2= LogisticRegressionCV(Cs=[C_pot1], cv=5, penalty='l1', refit=True,\n",
    "                                       solver='liblinear', random_state=42)\n",
    "    clf_l1_2.fit(X_train_LSA, y_train)\n",
    "    clf_l1_test_score.append(clf_l1_2.score(X_test_LSA, y_test))\n",
    "\n",
    "scores_l1_5fold = clf_l1.scores_\n",
    "c_opt_l1 = clf_l1.C_[0]\n",
    "k_opt_l1= log(c_opt_l1, 10)\n",
    "inv_c_opt_l1 = c_opt_l1**-1 #Each of the values in Cs describes the inverse of regularization strength\n",
    "print('Optimal k-value for L1: ', k_opt_l1)\n",
    "print('Optimal C-value: ', 10**k_opt_l1)\n",
    "print('This corresponds to an optimal regularization strength for L1 (inverse of C=10^k): ', \n",
    "      inv_c_opt_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Cross Validation Error rate vs L1 Regularization strength')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_l1 = []\n",
    "for l in range(0,7):\n",
    "    scores_l1.append(np.mean(scores_l1_5fold[1][:,l]))\n",
    "k_values = range(-3,4)\n",
    "plt.plot(np.asarray(k_values), 1-np.asarray(scores_l1))\n",
    "plt.xlabel(\"log of C value\")\n",
    "plt.ylabel(\"Cross Validation Error\")\n",
    "plt.title(\"Cross Validation Error rate vs L1 Regularization strength\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Test Error rate vs L1 Regularization strength')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_values = range(-3,4)\n",
    "plt.plot(np.asarray(k_values), 1-np.asarray(clf_l1_test_score))\n",
    "plt.xlabel(\"log of C value\")\n",
    "plt.ylabel(\"Test Eror\")\n",
    "plt.title(\"Test Error rate vs L1 Regularization strength\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see in the plot above that regularization decreases the test error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal k-value for L2:  2.0\n",
      "Optimal C-value:  100.0\n",
      "This corresponds to an optimal regularization strength for L2 (inverse of C=10^k):  0.01\n"
     ]
    }
   ],
   "source": [
    "clf_l2 = LogisticRegressionCV(Cs=C_pot, cv=5, penalty='l2', refit=True,\n",
    "                                       solver='liblinear', random_state=42)\n",
    "clf_l2.fit(X_train_LSA, y_train)\n",
    "scores_l2_5fold = clf_l2.scores_\n",
    "c_opt_l2 = clf_l2.C_[0]\n",
    "k_opt_l2= log(c_opt_l2, 10)\n",
    "inv_c_opt_l2 = c_opt_l2**-1 #Each of the values in Cs describes the inverse of \n",
    "                            #regularization strength\n",
    "\n",
    "print('Optimal k-value for L2: ', k_opt_l2)\n",
    "print('Optimal C-value: ', c_opt_l2)\n",
    "print('This corresponds to an optimal regularization strength for L2 (inverse of C=10^k): ', \n",
    "      inv_c_opt_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Cross Validation Error rate vs L2 Regularization strength')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_l2 = []\n",
    "for i in range(0,7):\n",
    "    scores_l2.append(np.mean(scores_l2_5fold[1][:,i]))\n",
    "plt.plot(np.asarray(k_values), 1-np.asarray(scores_l2))\n",
    "plt.xlabel(\"log of C value\")\n",
    "plt.ylabel(\"Cross Validation Error\")\n",
    "plt.title(\"Cross Validation Error rate vs L2 Regularization strength\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Test Error rate vs L2 Regularization strength')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_l2_test_score = []\n",
    "clf_l2.fit(X_train_LSA, y_train)\n",
    "for C_pot1 in C_pot:\n",
    "    clf_l2_2= LogisticRegressionCV(Cs=[C_pot1], cv=5, penalty='l1', refit=True,\n",
    "                                       solver='liblinear', random_state=42)\n",
    "    clf_l2_2.fit(X_train_LSA, y_train)\n",
    "    clf_l2_test_score.append(clf_l2_2.score(X_test_LSA, y_test))\n",
    "\n",
    "k_values = range(-3,4)\n",
    "plt.plot(np.asarray(k_values), 1-np.asarray(clf_l2_test_score))\n",
    "plt.xlabel(\"log of C value\")\n",
    "plt.ylabel(\"Test Eror\")\n",
    "plt.title(\"Test Error rate vs L2 Regularization strength\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the figure above we can clearly see as we increase the Regularization strength the cross validation error decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy score for unregularized:  0.9714285714285714 \n",
      "                           for l1:  0.9704761904761905 \n",
      "                           for l2:  0.9701587301587301\n",
      "   Recall score for unregularized:  0.9792452830188679 \n",
      "                           for l1:  0.9817610062893082 \n",
      "                           for l2:  0.9817610062893082\n",
      "Precision score for unregularized:  0.9646840148698885 \n",
      "                           for l1:  0.9606153846153846 \n",
      "                           for l2:  0.9600246002460024\n",
      "       F1 score for unregularized:  0.9719101123595505 \n",
      "                           for l1:  0.971073094867807 \n",
      "                           for l2:  0.9707711442786069\n"
     ]
    }
   ],
   "source": [
    "#Find the performance of best L1, best L2, No regularization test set performance\n",
    "\n",
    "#L1:\n",
    "clf_l1_opt    = LogisticRegression(penalty='l1', C=c_opt_l1, solver='liblinear', \n",
    "                                            random_state=42)\n",
    "clf_l1_opt.fit(X_train_LSA, y_train)\n",
    "y_pred_l1_opt = clf_l1_opt.predict(X_test_LSA)\n",
    "scores_l1_opt = clf_l1_opt.decision_function(X_test_LSA)\n",
    "\n",
    "#L2\n",
    "clf_l2_opt    = LogisticRegression(C=c_opt_l2, penalty='l2', solver='liblinear', \n",
    "                                            random_state=42)\n",
    "clf_l2_opt.fit(X_train_LSA, y_train)\n",
    "y_pred_l2_opt = clf_l2_opt.predict(X_test_LSA)\n",
    "scores_l2_opt = clf_l2_opt.decision_function(X_test_LSA)\n",
    "\n",
    "#L1: accuracy, recall, precision, f1 score\n",
    "accuracy_l1_opt  = accuracy_score(y_test, y_pred_l1_opt)\n",
    "recall_l1_opt    = recall_score(y_test, y_pred_l1_opt)\n",
    "precision_l1_opt = precision_score(y_test, y_pred_l1_opt)\n",
    "f1_score_l1_opt  = f1_score(y_test, y_pred_l1_opt)\n",
    "\n",
    "#L2: accuracy, recall, precision, f1 score\n",
    "accuracy_l2_opt  = accuracy_score(y_test, y_pred_l2_opt)\n",
    "recall_l2_opt    = recall_score(y_test, y_pred_l2_opt)\n",
    "precision_l2_opt = precision_score(y_test, y_pred_l2_opt)\n",
    "f1_score_l2_opt  = f1_score(y_test, y_pred_l2_opt)\n",
    "\n",
    "print(' Accuracy score for unregularized: ', unreg_accuracy, '\\n', \n",
    "      '                          for l1: ', accuracy_l1_opt, '\\n', \n",
    "      '                          for l2: ', accuracy_l2_opt)\n",
    "print('   Recall score for unregularized: ', unreg_recall, '\\n',\n",
    "      '                          for l1: ', recall_l1_opt, '\\n',\n",
    "      '                          for l2: ',  recall_l2_opt)\n",
    "print('Precision score for unregularized: ', unreg_precision, '\\n',\n",
    "      '                          for l1: ', precision_l1_opt, '\\n',\n",
    "      '                          for l2: ', precision_l2_opt)\n",
    "print('       F1 score for unregularized: ', unreg_f1_score, '\\n',\n",
    "      '                          for l1: ', f1_score_l1_opt, '\\n',\n",
    "      '                          for l2: ', f1_score_l2_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to the Report for analysis of Question5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quesiton 6\n",
    "Do binary classification with (Gaussian) Naive Bayes. Fits a Gaussian probability model to the given features to estimate the classes. Fit and predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NBclsfr = GaussianNB()\n",
    "NBclsfr.fit(X_train_LSA, y_train)\n",
    "y_pred_nb = NBclsfr.predict(X_test_LSA)\n",
    "NB_scores_prob = NBclsfr.predict_proba(X_test_LSA)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve:\n",
    "fpr_gaussian_nb, tpr_gaussian_nb, thresholds_gaussian_nb = roc_curve(\n",
    "    y_test, NB_scores_prob)\n",
    "\n",
    "# plot roc curves:\n",
    "plt.plot(fpr_gaussian_nb, tpr_gaussian_nb)\n",
    "plt.title('Gaussian Naive Bayes')\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of (Gaussian) Naive Bayes:   0.9015873015873016\n",
      "Recall of (Gaussian) Naive Bayes:     0.9723270440251572\n",
      "Precision of (Gaussian) Naive Bayes:  0.8532008830022075\n",
      "F1 score of (Gaussian) Naive Bayes:   0.9088771310993533\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "recall_nb = recall_score(y_test, y_pred_nb)\n",
    "precision_nb = precision_score(y_test, y_pred_nb)\n",
    "f1_score_nb = f1_score(y_test, y_pred_nb)\n",
    "\n",
    "plot_confusion_matrix(confusion_nb, title='(Gaussian) Naive Bayes confusion matrix')\n",
    "\n",
    "print('Accuracy of (Gaussian) Naive Bayes:  ', accuracy_nb)\n",
    "print('Recall of (Gaussian) Naive Bayes:    ', recall_nb)\n",
    "print('Precision of (Gaussian) Naive Bayes: ', precision_nb)\n",
    "print('F1 score of (Gaussian) Naive Bayes:  ', f1_score_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "Grid search paramters to make it easier to optimize. \n",
    "- Construct a pipeline to f=perform feature extraction, dimensionality reduction and classification\n",
    "- Do grid search with 5-fold cross-validation to compare\n",
    "    - removed headers and footers vs not\n",
    "    - min_df = 3 or 5\n",
    "    - lemmatization or not\n",
    "    - LSI or NMF\n",
    "    - SVM with the previously found gamma or L1 log or L2 log or GaussianNB\n",
    "    - else default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vector', CountVectorizer(analyzer=rmv_nums, #toggle this and 'word'\n",
    "                               min_df=3, #toggle min_df\n",
    "                               stop_words='english')),\n",
    "    ('tf-idf', TfidfTransformer()), # toggle this and  NMF\n",
    "    ('reduce_dim', TruncatedSVD(n_components=50, random_state=0)),\n",
    "    ('classify', GaussianNB()),    #toggle this and log reg's and SVM \n",
    "])\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'vector__analyzer': [rmv_nums, 'word'], # lemmatizations vs not\n",
    "        'vector__min_df': [3,5], # min df is 3 vs 5\n",
    "        'reduce_dim': [TruncatedSVD(n_components=50, random_state=42),\n",
    "                       NMF(n_components=50, init='random', random_state=42)],\n",
    "        'classify': [GaussianNB(), # Gaussian Naive Bayes\n",
    "                     LinearSVC(C=10, random_state=42), # SVC\n",
    "                     LogisticRegression(penalty='l1', random_state=42, solver='liblinear', C=10),\n",
    "                     LogisticRegression(penalty='l2', random_state=42, solver='liblinear', C=100)]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipeline, cv=5, n_jobs=-1, param_grid=param_grid, verbose=5, \n",
    "                    scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9102428722280888, total= 2.0min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.8152059134107709, total= 2.0min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.928194297782471, total= 2.0min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9112050739957717, total= 2.0min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.928042328042328, total= 2.1min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9208025343189018, total= 2.1min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.8848996832101372, total= 2.1min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.7972544878563886, total= 2.1min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.8848996832101372, total=   4.0s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9303062302006336, total=   3.9s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  7.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9154334038054969, total=   3.2s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9155227032734953, total=   3.7s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9185185185185185, total=   3.4s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9208025343189018, total=   3.1s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9239704329461457, total=   3.2s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.8954593453009504, total=   3.1s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.8953488372093024, total=   3.3s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9301587301587302, total=   3.6s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.8657505285412262, total= 2.1min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9333333333333333, total= 2.1min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.938753959873284, total= 2.8min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9366420274551215, total= 3.0min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9312896405919662, total= 2.9min[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9334741288278775, total= 3.0min\n",
      "\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 [CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "\n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9502645502645503, total= 3.0min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9524815205913411, total= 2.9min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.938753959873284, total= 2.5min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.941921858500528, total= 2.5min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9344608879492601, total= 2.6min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9493136219640972, total= 1.2min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9482576557550159, total= 1.2min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9428571428571428, total= 2.6min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9355179704016914, total=  47.8s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9514255543822597, total= 1.3min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.944973544973545, total= 1.4min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9398099260823654, total= 1.6min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9440337909186906, total= 1.2min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9312169312169312, total=  34.0s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9313621964097148, total=  58.3s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9408033826638478, total= 1.0min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9714889123548046, total= 2.1min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9809926082365364, total= 2.1min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9778247096092925, total= 2.1min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9682875264270613, total= 2.1min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9767195767195768, total= 2.1min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9725448785638859, total= 2.1min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9778247096092925, total= 2.1min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9672650475184794, total=   3.1s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9778247096092925, total= 2.1min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9746568109820486, total=   3.2s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9757127771911299, total=   3.6s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9735729386892178, total=   3.0s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9798941798941799, total=   3.6s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9683210137275607, total=   2.9s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9725448785638859, total=   3.3s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9757127771911299, total=   3.0s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.96723044397463, total=   3.3s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9788359788359788, total=   3.2s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9640591966173362, total= 2.1min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9767195767195768, total= 2.1min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9662090813093981, total= 2.8min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9640971488912354, total= 2.9min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9577167019027484, total= 2.9min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9619852164730729, total= 3.0min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 40.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9682539682539683, total= 3.0min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9683210137275607, total= 3.1min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9714889123548046, total= 2.7min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9651531151003168, total= 2.8min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9693769799366421, total=  57.9s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9609292502639916, total=  59.6s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9556025369978859, total= 2.7min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9661375661375662, total= 2.8min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9630021141649049, total=  34.1s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9651531151003168, total= 1.2min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9756613756613757, total= 1.2min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9693769799366421, total= 1.1min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9662090813093981, total= 1.1min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9693121693121693, total=  27.6s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9619852164730729, total= 1.0min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9608879492600423, total=  52.9s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9704329461457233, total= 2.3min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9799366420274551, total= 2.2min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9767687434002112, total= 2.2min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9682875264270613, total= 2.2min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9777777777777777, total= 1.9min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9725448785638859, total= 1.9min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9788806758183738, total= 1.9min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9725448785638859, total=   2.9s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9714889123548046, total=   2.6s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9788806758183738, total= 1.9min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9767687434002112, total=   2.8s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9725158562367865, total=   3.1s\n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9798941798941799, total=   3.1s[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9736008447729673, total=   2.7s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9714889123548046, total=   3.1s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9757127771911299, total=   2.5s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9682875264270613, total=   2.7s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9788359788359788, total=   2.4s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.96723044397463, total= 1.9min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9777777777777777, total= 1.9min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9704329461457233, total= 2.7min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9630411826821542, total= 2.9min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9704329461457233, total= 2.6min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9693446088794926, total= 2.5min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9767195767195768, total= 2.8min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9683210137275607, total= 2.8min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9736008447729673, total= 2.7min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9725448785638859, total= 2.7min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9651531151003168, total=  58.2s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9651531151003168, total=  56.7s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.959830866807611, total= 2.6min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9735449735449735, total= 2.6min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9661733615221987, total=  30.6s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9693769799366421, total= 1.1min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9619852164730729, total=  56.8s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9735449735449735, total= 1.1min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9683210137275607, total=  57.3s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9714285714285714, total=  28.7s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9651531151003168, total=  53.8s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9608879492600423, total=  45.9s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9725448785638859, total= 2.0min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9809926082365364, total= 1.9min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9778247096092925, total= 1.9min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.96723044397463, total= 1.9min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9767195767195768, total= 2.2min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9714889123548046, total= 2.1min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9778247096092925, total= 2.1min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9704329461457233, total=   3.0s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9736008447729673, total=   3.3s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9778247096092925, total= 2.1min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9757127771911299, total=   2.9s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9714587737843552, total=   2.6s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9798941798941799, total=   3.0s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9704329461457233, total=   2.9s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9725448785638859, total=   3.3s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9736008447729673, total=   2.5s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9693446088794926, total=   2.4s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9777777777777777, total=   2.6s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9651162790697675, total= 2.0min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9767195767195768, total= 1.9min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9662090813093981, total= 2.4min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9640971488912354, total= 2.6min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9619852164730729, total= 2.7min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9608879492600423, total= 2.6min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9693121693121693, total= 2.7min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9693769799366421, total= 2.6min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9651531151003168, total= 2.4min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9725448785638859, total= 2.5min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9609292502639916, total=  56.7s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9683210137275607, total=  58.5s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9566596194503171, total= 2.5min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.964021164021164, total= 2.5min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9640591966173362, total=  31.4s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9619852164730729, total= 1.2min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9735449735449735, total= 1.1min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9672650475184794, total=  55.8s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9704329461457233, total=  59.2s\n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9693121693121693, total=  25.1s\n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9630411826821542, total=  44.0s\n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9630021141649049, total=  42.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed: 102.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time is:  6190.921961069107\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "grid.fit(train_dataset.data, y_train)\n",
    "end = time.time()\n",
    "print(\"run time is: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarat/packages/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/sarat/packages/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/sarat/packages/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/sarat/packages/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/sarat/packages/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/sarat/packages/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/sarat/packages/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classify</th>\n",
       "      <th>param_reduce_dim</th>\n",
       "      <th>param_vector__analyzer</th>\n",
       "      <th>param_vector__min_df</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.433782</td>\n",
       "      <td>1.983841</td>\n",
       "      <td>24.230762</td>\n",
       "      <td>1.497332</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': GaussianNB(priors=None), 'reduce_...</td>\n",
       "      <td>0.928194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898563</td>\n",
       "      <td>0.042416</td>\n",
       "      <td>31</td>\n",
       "      <td>0.929458</td>\n",
       "      <td>0.906737</td>\n",
       "      <td>0.842272</td>\n",
       "      <td>0.907818</td>\n",
       "      <td>0.930024</td>\n",
       "      <td>0.903262</td>\n",
       "      <td>0.032109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.119900</td>\n",
       "      <td>1.218594</td>\n",
       "      <td>24.499773</td>\n",
       "      <td>1.311629</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': GaussianNB(priors=None), 'reduce_...</td>\n",
       "      <td>0.920803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880389</td>\n",
       "      <td>0.048132</td>\n",
       "      <td>32</td>\n",
       "      <td>0.917834</td>\n",
       "      <td>0.885337</td>\n",
       "      <td>0.833554</td>\n",
       "      <td>0.873217</td>\n",
       "      <td>0.924743</td>\n",
       "      <td>0.886937</td>\n",
       "      <td>0.032938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.210907</td>\n",
       "      <td>0.282175</td>\n",
       "      <td>0.433967</td>\n",
       "      <td>0.045136</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': GaussianNB(priors=None), 'reduce_...</td>\n",
       "      <td>0.884900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912933</td>\n",
       "      <td>0.015050</td>\n",
       "      <td>30</td>\n",
       "      <td>0.904888</td>\n",
       "      <td>0.928402</td>\n",
       "      <td>0.913342</td>\n",
       "      <td>0.912044</td>\n",
       "      <td>0.894904</td>\n",
       "      <td>0.910716</td>\n",
       "      <td>0.011004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.898037</td>\n",
       "      <td>0.171780</td>\n",
       "      <td>0.363549</td>\n",
       "      <td>0.027997</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': GaussianNB(priors=None), 'reduce_...</td>\n",
       "      <td>0.920803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913145</td>\n",
       "      <td>0.014795</td>\n",
       "      <td>29</td>\n",
       "      <td>0.923910</td>\n",
       "      <td>0.919947</td>\n",
       "      <td>0.896697</td>\n",
       "      <td>0.886424</td>\n",
       "      <td>0.918669</td>\n",
       "      <td>0.909130</td>\n",
       "      <td>0.014809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>148.772296</td>\n",
       "      <td>5.360785</td>\n",
       "      <td>25.577251</td>\n",
       "      <td>1.781800</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': GaussianNB(priors=None), 'reduce_...</td>\n",
       "      <td>0.936642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938081</td>\n",
       "      <td>0.006604</td>\n",
       "      <td>28</td>\n",
       "      <td>0.936856</td>\n",
       "      <td>0.937649</td>\n",
       "      <td>0.942668</td>\n",
       "      <td>0.938193</td>\n",
       "      <td>0.942171</td>\n",
       "      <td>0.939507</td>\n",
       "      <td>0.002421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>135.187867</td>\n",
       "      <td>9.174068</td>\n",
       "      <td>22.972236</td>\n",
       "      <td>1.775968</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': GaussianNB(priors=None), 'reduce_...</td>\n",
       "      <td>0.952482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942096</td>\n",
       "      <td>0.005966</td>\n",
       "      <td>26</td>\n",
       "      <td>0.944782</td>\n",
       "      <td>0.940026</td>\n",
       "      <td>0.937120</td>\n",
       "      <td>0.937929</td>\n",
       "      <td>0.933721</td>\n",
       "      <td>0.938716</td>\n",
       "      <td>0.003651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73.791991</td>\n",
       "      <td>16.335032</td>\n",
       "      <td>0.780611</td>\n",
       "      <td>0.193678</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': GaussianNB(priors=None), 'reduce_...</td>\n",
       "      <td>0.949314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.943576</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>25</td>\n",
       "      <td>0.944782</td>\n",
       "      <td>0.946631</td>\n",
       "      <td>0.942404</td>\n",
       "      <td>0.946117</td>\n",
       "      <td>0.942435</td>\n",
       "      <td>0.944474</td>\n",
       "      <td>0.001783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>59.657339</td>\n",
       "      <td>15.056507</td>\n",
       "      <td>0.694482</td>\n",
       "      <td>0.133898</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': GaussianNB(priors=None), 'reduce_...</td>\n",
       "      <td>0.951426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939772</td>\n",
       "      <td>0.007733</td>\n",
       "      <td>27</td>\n",
       "      <td>0.947952</td>\n",
       "      <td>0.940819</td>\n",
       "      <td>0.933421</td>\n",
       "      <td>0.942684</td>\n",
       "      <td>0.935833</td>\n",
       "      <td>0.940142</td>\n",
       "      <td>0.005131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100.699575</td>\n",
       "      <td>2.238069</td>\n",
       "      <td>25.299938</td>\n",
       "      <td>1.681110</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LinearSVC(C=10, class_weight=None...</td>\n",
       "      <td>0.971489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975063</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979128</td>\n",
       "      <td>0.976222</td>\n",
       "      <td>0.978071</td>\n",
       "      <td>0.980718</td>\n",
       "      <td>0.978083</td>\n",
       "      <td>0.978445</td>\n",
       "      <td>0.001473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100.648767</td>\n",
       "      <td>1.831733</td>\n",
       "      <td>25.563081</td>\n",
       "      <td>1.382796</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LinearSVC(C=10, class_weight=None...</td>\n",
       "      <td>0.972545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973795</td>\n",
       "      <td>0.005241</td>\n",
       "      <td>8</td>\n",
       "      <td>0.978336</td>\n",
       "      <td>0.975958</td>\n",
       "      <td>0.978071</td>\n",
       "      <td>0.979398</td>\n",
       "      <td>0.978875</td>\n",
       "      <td>0.978127</td>\n",
       "      <td>0.001177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.893525</td>\n",
       "      <td>0.232115</td>\n",
       "      <td>0.381756</td>\n",
       "      <td>0.066687</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LinearSVC(C=10, class_weight=None...</td>\n",
       "      <td>0.967265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974218</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>6</td>\n",
       "      <td>0.978336</td>\n",
       "      <td>0.978336</td>\n",
       "      <td>0.976750</td>\n",
       "      <td>0.979926</td>\n",
       "      <td>0.978875</td>\n",
       "      <td>0.978445</td>\n",
       "      <td>0.001027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.763265</td>\n",
       "      <td>0.151874</td>\n",
       "      <td>0.379076</td>\n",
       "      <td>0.023187</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LinearSVC(C=10, class_weight=None...</td>\n",
       "      <td>0.968321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972527</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>12</td>\n",
       "      <td>0.978600</td>\n",
       "      <td>0.977015</td>\n",
       "      <td>0.976750</td>\n",
       "      <td>0.978341</td>\n",
       "      <td>0.978347</td>\n",
       "      <td>0.977811</td>\n",
       "      <td>0.000768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>150.530996</td>\n",
       "      <td>3.820548</td>\n",
       "      <td>25.736102</td>\n",
       "      <td>2.721967</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LinearSVC(C=10, class_weight=None...</td>\n",
       "      <td>0.964097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963652</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>24</td>\n",
       "      <td>0.961162</td>\n",
       "      <td>0.966711</td>\n",
       "      <td>0.964333</td>\n",
       "      <td>0.963814</td>\n",
       "      <td>0.961711</td>\n",
       "      <td>0.963546</td>\n",
       "      <td>0.001988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>142.927140</td>\n",
       "      <td>8.152500</td>\n",
       "      <td>25.224422</td>\n",
       "      <td>1.963361</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LinearSVC(C=10, class_weight=None...</td>\n",
       "      <td>0.968321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965342</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>22</td>\n",
       "      <td>0.967768</td>\n",
       "      <td>0.962219</td>\n",
       "      <td>0.964333</td>\n",
       "      <td>0.964871</td>\n",
       "      <td>0.963031</td>\n",
       "      <td>0.964444</td>\n",
       "      <td>0.001907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>58.531318</td>\n",
       "      <td>13.894054</td>\n",
       "      <td>0.646701</td>\n",
       "      <td>0.169632</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LinearSVC(C=10, class_weight=None...</td>\n",
       "      <td>0.969377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966822</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>16</td>\n",
       "      <td>0.968824</td>\n",
       "      <td>0.964597</td>\n",
       "      <td>0.964333</td>\n",
       "      <td>0.961965</td>\n",
       "      <td>0.963560</td>\n",
       "      <td>0.964656</td>\n",
       "      <td>0.002277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>53.342262</td>\n",
       "      <td>13.973858</td>\n",
       "      <td>0.659960</td>\n",
       "      <td>0.165860</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LinearSVC(C=10, class_weight=None...</td>\n",
       "      <td>0.969377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965554</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>19</td>\n",
       "      <td>0.968824</td>\n",
       "      <td>0.964069</td>\n",
       "      <td>0.962748</td>\n",
       "      <td>0.964871</td>\n",
       "      <td>0.965408</td>\n",
       "      <td>0.965184</td>\n",
       "      <td>0.002029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>104.191622</td>\n",
       "      <td>7.066336</td>\n",
       "      <td>25.431193</td>\n",
       "      <td>0.746033</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LogisticRegression(C=10, class_we...</td>\n",
       "      <td>0.970433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974641</td>\n",
       "      <td>0.004483</td>\n",
       "      <td>4</td>\n",
       "      <td>0.978071</td>\n",
       "      <td>0.976486</td>\n",
       "      <td>0.978600</td>\n",
       "      <td>0.980190</td>\n",
       "      <td>0.979403</td>\n",
       "      <td>0.978550</td>\n",
       "      <td>0.001258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>91.429162</td>\n",
       "      <td>3.105124</td>\n",
       "      <td>22.757135</td>\n",
       "      <td>1.574231</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LogisticRegression(C=10, class_we...</td>\n",
       "      <td>0.972545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975063</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978336</td>\n",
       "      <td>0.976486</td>\n",
       "      <td>0.978071</td>\n",
       "      <td>0.980454</td>\n",
       "      <td>0.978875</td>\n",
       "      <td>0.978444</td>\n",
       "      <td>0.001281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.552921</td>\n",
       "      <td>0.201793</td>\n",
       "      <td>0.344039</td>\n",
       "      <td>0.019574</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LogisticRegression(C=10, class_we...</td>\n",
       "      <td>0.972545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974641</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>4</td>\n",
       "      <td>0.978071</td>\n",
       "      <td>0.978600</td>\n",
       "      <td>0.976486</td>\n",
       "      <td>0.980718</td>\n",
       "      <td>0.977819</td>\n",
       "      <td>0.978339</td>\n",
       "      <td>0.001379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.384326</td>\n",
       "      <td>0.251352</td>\n",
       "      <td>0.304661</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LogisticRegression(C=10, class_we...</td>\n",
       "      <td>0.971489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973584</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>10</td>\n",
       "      <td>0.978864</td>\n",
       "      <td>0.978600</td>\n",
       "      <td>0.977279</td>\n",
       "      <td>0.979926</td>\n",
       "      <td>0.976234</td>\n",
       "      <td>0.978181</td>\n",
       "      <td>0.001288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>136.578877</td>\n",
       "      <td>5.636614</td>\n",
       "      <td>24.892671</td>\n",
       "      <td>2.457048</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LogisticRegression(C=10, class_we...</td>\n",
       "      <td>0.963041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969992</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>13</td>\n",
       "      <td>0.965125</td>\n",
       "      <td>0.971466</td>\n",
       "      <td>0.969617</td>\n",
       "      <td>0.968568</td>\n",
       "      <td>0.966200</td>\n",
       "      <td>0.968195</td>\n",
       "      <td>0.002292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>139.121033</td>\n",
       "      <td>3.291227</td>\n",
       "      <td>22.841277</td>\n",
       "      <td>1.959186</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LogisticRegression(C=10, class_we...</td>\n",
       "      <td>0.968321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969569</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>14</td>\n",
       "      <td>0.974108</td>\n",
       "      <td>0.968296</td>\n",
       "      <td>0.972787</td>\n",
       "      <td>0.971474</td>\n",
       "      <td>0.968577</td>\n",
       "      <td>0.971048</td>\n",
       "      <td>0.002291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>54.032435</td>\n",
       "      <td>12.432272</td>\n",
       "      <td>0.681182</td>\n",
       "      <td>0.092079</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LogisticRegression(C=10, class_we...</td>\n",
       "      <td>0.965153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967878</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>15</td>\n",
       "      <td>0.970410</td>\n",
       "      <td>0.968824</td>\n",
       "      <td>0.967768</td>\n",
       "      <td>0.966455</td>\n",
       "      <td>0.967520</td>\n",
       "      <td>0.968195</td>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>47.925445</td>\n",
       "      <td>10.703765</td>\n",
       "      <td>0.575351</td>\n",
       "      <td>0.145613</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LogisticRegression(C=10, class_we...</td>\n",
       "      <td>0.961985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965554</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>19</td>\n",
       "      <td>0.972259</td>\n",
       "      <td>0.968032</td>\n",
       "      <td>0.963804</td>\n",
       "      <td>0.969625</td>\n",
       "      <td>0.971217</td>\n",
       "      <td>0.968987</td>\n",
       "      <td>0.002962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>96.635608</td>\n",
       "      <td>4.733885</td>\n",
       "      <td>22.185658</td>\n",
       "      <td>1.966249</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LogisticRegression(C=100, class_w...</td>\n",
       "      <td>0.972545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975063</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977543</td>\n",
       "      <td>0.976486</td>\n",
       "      <td>0.977543</td>\n",
       "      <td>0.979398</td>\n",
       "      <td>0.979139</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.001092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100.839790</td>\n",
       "      <td>6.123746</td>\n",
       "      <td>22.009466</td>\n",
       "      <td>0.890195</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LogisticRegression(C=100, class_w...</td>\n",
       "      <td>0.971489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973795</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>8</td>\n",
       "      <td>0.978336</td>\n",
       "      <td>0.975958</td>\n",
       "      <td>0.978071</td>\n",
       "      <td>0.979398</td>\n",
       "      <td>0.978611</td>\n",
       "      <td>0.978075</td>\n",
       "      <td>0.001148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.627176</td>\n",
       "      <td>0.197776</td>\n",
       "      <td>0.336569</td>\n",
       "      <td>0.039981</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LogisticRegression(C=100, class_w...</td>\n",
       "      <td>0.970433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974218</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>6</td>\n",
       "      <td>0.978336</td>\n",
       "      <td>0.978864</td>\n",
       "      <td>0.976486</td>\n",
       "      <td>0.979134</td>\n",
       "      <td>0.978875</td>\n",
       "      <td>0.978339</td>\n",
       "      <td>0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.403638</td>\n",
       "      <td>0.297489</td>\n",
       "      <td>0.343731</td>\n",
       "      <td>0.034080</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LogisticRegression(C=100, class_w...</td>\n",
       "      <td>0.970433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972739</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>11</td>\n",
       "      <td>0.978071</td>\n",
       "      <td>0.977807</td>\n",
       "      <td>0.976486</td>\n",
       "      <td>0.978605</td>\n",
       "      <td>0.978347</td>\n",
       "      <td>0.977863</td>\n",
       "      <td>0.000739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>134.332230</td>\n",
       "      <td>5.719242</td>\n",
       "      <td>22.516707</td>\n",
       "      <td>1.635513</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LogisticRegression(C=100, class_w...</td>\n",
       "      <td>0.964097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964497</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>23</td>\n",
       "      <td>0.960634</td>\n",
       "      <td>0.966711</td>\n",
       "      <td>0.965125</td>\n",
       "      <td>0.964078</td>\n",
       "      <td>0.961447</td>\n",
       "      <td>0.963599</td>\n",
       "      <td>0.002266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>128.671017</td>\n",
       "      <td>5.435246</td>\n",
       "      <td>22.015299</td>\n",
       "      <td>1.318149</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LogisticRegression(C=100, class_w...</td>\n",
       "      <td>0.969377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965554</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>19</td>\n",
       "      <td>0.967503</td>\n",
       "      <td>0.963276</td>\n",
       "      <td>0.964333</td>\n",
       "      <td>0.965663</td>\n",
       "      <td>0.962503</td>\n",
       "      <td>0.964656</td>\n",
       "      <td>0.001776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>55.648391</td>\n",
       "      <td>13.440623</td>\n",
       "      <td>0.610433</td>\n",
       "      <td>0.080020</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LogisticRegression(C=100, class_w...</td>\n",
       "      <td>0.968321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965765</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>18</td>\n",
       "      <td>0.969353</td>\n",
       "      <td>0.965125</td>\n",
       "      <td>0.964861</td>\n",
       "      <td>0.963022</td>\n",
       "      <td>0.965672</td>\n",
       "      <td>0.965607</td>\n",
       "      <td>0.002074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>44.829342</td>\n",
       "      <td>12.031654</td>\n",
       "      <td>0.504168</td>\n",
       "      <td>0.198360</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LogisticRegression(C=100, class_w...</td>\n",
       "      <td>0.967265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966610</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>17</td>\n",
       "      <td>0.968032</td>\n",
       "      <td>0.963540</td>\n",
       "      <td>0.963012</td>\n",
       "      <td>0.964606</td>\n",
       "      <td>0.965936</td>\n",
       "      <td>0.965025</td>\n",
       "      <td>0.001806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       97.433782      1.983841        24.230762        1.497332   \n",
       "1      102.119900      1.218594        24.499773        1.311629   \n",
       "2        3.210907      0.282175         0.433967        0.045136   \n",
       "3        2.898037      0.171780         0.363549        0.027997   \n",
       "4      148.772296      5.360785        25.577251        1.781800   \n",
       "5      135.187867      9.174068        22.972236        1.775968   \n",
       "6       73.791991     16.335032         0.780611        0.193678   \n",
       "7       59.657339     15.056507         0.694482        0.133898   \n",
       "8      100.699575      2.238069        25.299938        1.681110   \n",
       "9      100.648767      1.831733        25.563081        1.382796   \n",
       "10       2.893525      0.232115         0.381756        0.066687   \n",
       "11       2.763265      0.151874         0.379076        0.023187   \n",
       "12     150.530996      3.820548        25.736102        2.721967   \n",
       "13     142.927140      8.152500        25.224422        1.963361   \n",
       "14      58.531318     13.894054         0.646701        0.169632   \n",
       "15      53.342262     13.973858         0.659960        0.165860   \n",
       "16     104.191622      7.066336        25.431193        0.746033   \n",
       "17      91.429162      3.105124        22.757135        1.574231   \n",
       "18       2.552921      0.201793         0.344039        0.019574   \n",
       "19       2.384326      0.251352         0.304661        0.017297   \n",
       "20     136.578877      5.636614        24.892671        2.457048   \n",
       "21     139.121033      3.291227        22.841277        1.959186   \n",
       "22      54.032435     12.432272         0.681182        0.092079   \n",
       "23      47.925445     10.703765         0.575351        0.145613   \n",
       "24      96.635608      4.733885        22.185658        1.966249   \n",
       "25     100.839790      6.123746        22.009466        0.890195   \n",
       "26       2.627176      0.197776         0.336569        0.039981   \n",
       "27       2.403638      0.297489         0.343731        0.034080   \n",
       "28     134.332230      5.719242        22.516707        1.635513   \n",
       "29     128.671017      5.435246        22.015299        1.318149   \n",
       "30      55.648391     13.440623         0.610433        0.080020   \n",
       "31      44.829342     12.031654         0.504168        0.198360   \n",
       "\n",
       "                                       param_classify  \\\n",
       "0                             GaussianNB(priors=None)   \n",
       "1                             GaussianNB(priors=None)   \n",
       "2                             GaussianNB(priors=None)   \n",
       "3                             GaussianNB(priors=None)   \n",
       "4                             GaussianNB(priors=None)   \n",
       "5                             GaussianNB(priors=None)   \n",
       "6                             GaussianNB(priors=None)   \n",
       "7                             GaussianNB(priors=None)   \n",
       "8   LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "9   LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "10  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "11  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "12  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "13  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "14  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "15  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "16  LogisticRegression(C=10, class_weight=None, du...   \n",
       "17  LogisticRegression(C=10, class_weight=None, du...   \n",
       "18  LogisticRegression(C=10, class_weight=None, du...   \n",
       "19  LogisticRegression(C=10, class_weight=None, du...   \n",
       "20  LogisticRegression(C=10, class_weight=None, du...   \n",
       "21  LogisticRegression(C=10, class_weight=None, du...   \n",
       "22  LogisticRegression(C=10, class_weight=None, du...   \n",
       "23  LogisticRegression(C=10, class_weight=None, du...   \n",
       "24  LogisticRegression(C=100, class_weight=None, d...   \n",
       "25  LogisticRegression(C=100, class_weight=None, d...   \n",
       "26  LogisticRegression(C=100, class_weight=None, d...   \n",
       "27  LogisticRegression(C=100, class_weight=None, d...   \n",
       "28  LogisticRegression(C=100, class_weight=None, d...   \n",
       "29  LogisticRegression(C=100, class_weight=None, d...   \n",
       "30  LogisticRegression(C=100, class_weight=None, d...   \n",
       "31  LogisticRegression(C=100, class_weight=None, d...   \n",
       "\n",
       "                                     param_reduce_dim  \\\n",
       "0   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "1   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "2   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "3   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "4   NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "5   NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "6   NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "7   NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "8   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "9   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "10  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "11  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "12  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "13  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "14  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "15  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "16  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "17  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "18  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "19  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "20  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "21  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "22  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "23  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "24  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "25  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "26  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "27  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "28  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "29  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "30  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "31  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "\n",
       "                   param_vector__analyzer param_vector__min_df  \\\n",
       "0   <function rmv_nums at 0x7f916a205e18>                    3   \n",
       "1   <function rmv_nums at 0x7f916a205e18>                    5   \n",
       "2                                    word                    3   \n",
       "3                                    word                    5   \n",
       "4   <function rmv_nums at 0x7f916a205e18>                    3   \n",
       "5   <function rmv_nums at 0x7f916a205e18>                    5   \n",
       "6                                    word                    3   \n",
       "7                                    word                    5   \n",
       "8   <function rmv_nums at 0x7f916a205e18>                    3   \n",
       "9   <function rmv_nums at 0x7f916a205e18>                    5   \n",
       "10                                   word                    3   \n",
       "11                                   word                    5   \n",
       "12  <function rmv_nums at 0x7f916a205e18>                    3   \n",
       "13  <function rmv_nums at 0x7f916a205e18>                    5   \n",
       "14                                   word                    3   \n",
       "15                                   word                    5   \n",
       "16  <function rmv_nums at 0x7f916a205e18>                    3   \n",
       "17  <function rmv_nums at 0x7f916a205e18>                    5   \n",
       "18                                   word                    3   \n",
       "19                                   word                    5   \n",
       "20  <function rmv_nums at 0x7f916a205e18>                    3   \n",
       "21  <function rmv_nums at 0x7f916a205e18>                    5   \n",
       "22                                   word                    3   \n",
       "23                                   word                    5   \n",
       "24  <function rmv_nums at 0x7f916a205e18>                    3   \n",
       "25  <function rmv_nums at 0x7f916a205e18>                    5   \n",
       "26                                   word                    3   \n",
       "27                                   word                    5   \n",
       "28  <function rmv_nums at 0x7f916a205e18>                    3   \n",
       "29  <function rmv_nums at 0x7f916a205e18>                    5   \n",
       "30                                   word                    3   \n",
       "31                                   word                    5   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'classify': GaussianNB(priors=None), 'reduce_...           0.928194   \n",
       "1   {'classify': GaussianNB(priors=None), 'reduce_...           0.920803   \n",
       "2   {'classify': GaussianNB(priors=None), 'reduce_...           0.884900   \n",
       "3   {'classify': GaussianNB(priors=None), 'reduce_...           0.920803   \n",
       "4   {'classify': GaussianNB(priors=None), 'reduce_...           0.936642   \n",
       "5   {'classify': GaussianNB(priors=None), 'reduce_...           0.952482   \n",
       "6   {'classify': GaussianNB(priors=None), 'reduce_...           0.949314   \n",
       "7   {'classify': GaussianNB(priors=None), 'reduce_...           0.951426   \n",
       "8   {'classify': LinearSVC(C=10, class_weight=None...           0.971489   \n",
       "9   {'classify': LinearSVC(C=10, class_weight=None...           0.972545   \n",
       "10  {'classify': LinearSVC(C=10, class_weight=None...           0.967265   \n",
       "11  {'classify': LinearSVC(C=10, class_weight=None...           0.968321   \n",
       "12  {'classify': LinearSVC(C=10, class_weight=None...           0.964097   \n",
       "13  {'classify': LinearSVC(C=10, class_weight=None...           0.968321   \n",
       "14  {'classify': LinearSVC(C=10, class_weight=None...           0.969377   \n",
       "15  {'classify': LinearSVC(C=10, class_weight=None...           0.969377   \n",
       "16  {'classify': LogisticRegression(C=10, class_we...           0.970433   \n",
       "17  {'classify': LogisticRegression(C=10, class_we...           0.972545   \n",
       "18  {'classify': LogisticRegression(C=10, class_we...           0.972545   \n",
       "19  {'classify': LogisticRegression(C=10, class_we...           0.971489   \n",
       "20  {'classify': LogisticRegression(C=10, class_we...           0.963041   \n",
       "21  {'classify': LogisticRegression(C=10, class_we...           0.968321   \n",
       "22  {'classify': LogisticRegression(C=10, class_we...           0.965153   \n",
       "23  {'classify': LogisticRegression(C=10, class_we...           0.961985   \n",
       "24  {'classify': LogisticRegression(C=100, class_w...           0.972545   \n",
       "25  {'classify': LogisticRegression(C=100, class_w...           0.971489   \n",
       "26  {'classify': LogisticRegression(C=100, class_w...           0.970433   \n",
       "27  {'classify': LogisticRegression(C=100, class_w...           0.970433   \n",
       "28  {'classify': LogisticRegression(C=100, class_w...           0.964097   \n",
       "29  {'classify': LogisticRegression(C=100, class_w...           0.969377   \n",
       "30  {'classify': LogisticRegression(C=100, class_w...           0.968321   \n",
       "31  {'classify': LogisticRegression(C=100, class_w...           0.967265   \n",
       "\n",
       "         ...         mean_test_score  std_test_score  rank_test_score  \\\n",
       "0        ...                0.898563        0.042416               31   \n",
       "1        ...                0.880389        0.048132               32   \n",
       "2        ...                0.912933        0.015050               30   \n",
       "3        ...                0.913145        0.014795               29   \n",
       "4        ...                0.938081        0.006604               28   \n",
       "5        ...                0.942096        0.005966               26   \n",
       "6        ...                0.943576        0.005214               25   \n",
       "7        ...                0.939772        0.007733               27   \n",
       "8        ...                0.975063        0.004566                1   \n",
       "9        ...                0.973795        0.005241                8   \n",
       "10       ...                0.974218        0.004084                6   \n",
       "11       ...                0.972527        0.004374               12   \n",
       "12       ...                0.963652        0.003630               24   \n",
       "13       ...                0.965342        0.005332               22   \n",
       "14       ...                0.966822        0.005228               16   \n",
       "15       ...                0.965554        0.003568               19   \n",
       "16       ...                0.974641        0.004483                4   \n",
       "17       ...                0.975063        0.004565                1   \n",
       "18       ...                0.974641        0.003192                4   \n",
       "19       ...                0.973584        0.003592               10   \n",
       "20       ...                0.969992        0.004344               13   \n",
       "21       ...                0.969569        0.005240               14   \n",
       "22       ...                0.967878        0.003227               15   \n",
       "23       ...                0.965554        0.003919               19   \n",
       "24       ...                0.975063        0.004759                1   \n",
       "25       ...                0.973795        0.004933                8   \n",
       "26       ...                0.974218        0.003369                6   \n",
       "27       ...                0.972739        0.002932               11   \n",
       "28       ...                0.964497        0.003019               23   \n",
       "29       ...                0.965554        0.005387               19   \n",
       "30       ...                0.965765        0.004639               18   \n",
       "31       ...                0.966610        0.003102               17   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0             0.929458            0.906737            0.842272   \n",
       "1             0.917834            0.885337            0.833554   \n",
       "2             0.904888            0.928402            0.913342   \n",
       "3             0.923910            0.919947            0.896697   \n",
       "4             0.936856            0.937649            0.942668   \n",
       "5             0.944782            0.940026            0.937120   \n",
       "6             0.944782            0.946631            0.942404   \n",
       "7             0.947952            0.940819            0.933421   \n",
       "8             0.979128            0.976222            0.978071   \n",
       "9             0.978336            0.975958            0.978071   \n",
       "10            0.978336            0.978336            0.976750   \n",
       "11            0.978600            0.977015            0.976750   \n",
       "12            0.961162            0.966711            0.964333   \n",
       "13            0.967768            0.962219            0.964333   \n",
       "14            0.968824            0.964597            0.964333   \n",
       "15            0.968824            0.964069            0.962748   \n",
       "16            0.978071            0.976486            0.978600   \n",
       "17            0.978336            0.976486            0.978071   \n",
       "18            0.978071            0.978600            0.976486   \n",
       "19            0.978864            0.978600            0.977279   \n",
       "20            0.965125            0.971466            0.969617   \n",
       "21            0.974108            0.968296            0.972787   \n",
       "22            0.970410            0.968824            0.967768   \n",
       "23            0.972259            0.968032            0.963804   \n",
       "24            0.977543            0.976486            0.977543   \n",
       "25            0.978336            0.975958            0.978071   \n",
       "26            0.978336            0.978864            0.976486   \n",
       "27            0.978071            0.977807            0.976486   \n",
       "28            0.960634            0.966711            0.965125   \n",
       "29            0.967503            0.963276            0.964333   \n",
       "30            0.969353            0.965125            0.964861   \n",
       "31            0.968032            0.963540            0.963012   \n",
       "\n",
       "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0             0.907818            0.930024          0.903262         0.032109  \n",
       "1             0.873217            0.924743          0.886937         0.032938  \n",
       "2             0.912044            0.894904          0.910716         0.011004  \n",
       "3             0.886424            0.918669          0.909130         0.014809  \n",
       "4             0.938193            0.942171          0.939507         0.002421  \n",
       "5             0.937929            0.933721          0.938716         0.003651  \n",
       "6             0.946117            0.942435          0.944474         0.001783  \n",
       "7             0.942684            0.935833          0.940142         0.005131  \n",
       "8             0.980718            0.978083          0.978445         0.001473  \n",
       "9             0.979398            0.978875          0.978127         0.001177  \n",
       "10            0.979926            0.978875          0.978445         0.001027  \n",
       "11            0.978341            0.978347          0.977811         0.000768  \n",
       "12            0.963814            0.961711          0.963546         0.001988  \n",
       "13            0.964871            0.963031          0.964444         0.001907  \n",
       "14            0.961965            0.963560          0.964656         0.002277  \n",
       "15            0.964871            0.965408          0.965184         0.002029  \n",
       "16            0.980190            0.979403          0.978550         0.001258  \n",
       "17            0.980454            0.978875          0.978444         0.001281  \n",
       "18            0.980718            0.977819          0.978339         0.001379  \n",
       "19            0.979926            0.976234          0.978181         0.001288  \n",
       "20            0.968568            0.966200          0.968195         0.002292  \n",
       "21            0.971474            0.968577          0.971048         0.002291  \n",
       "22            0.966455            0.967520          0.968195         0.001339  \n",
       "23            0.969625            0.971217          0.968987         0.002962  \n",
       "24            0.979398            0.979139          0.978022         0.001092  \n",
       "25            0.979398            0.978611          0.978075         0.001148  \n",
       "26            0.979134            0.978875          0.978339         0.000962  \n",
       "27            0.978605            0.978347          0.977863         0.000739  \n",
       "28            0.964078            0.961447          0.963599         0.002266  \n",
       "29            0.965663            0.962503          0.964656         0.001776  \n",
       "30            0.963022            0.965672          0.965607         0.002074  \n",
       "31            0.964606            0.965936          0.965025         0.001806  \n",
       "\n",
       "[32 rows x 24 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove header and footer from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_noheaders = fetch_20newsgroups(subset = 'train', \n",
    "                                   categories=comp_categories+rec_categories, \n",
    "                                   remove=('headers', 'footers'), #toggle head/foot\n",
    "                                   shuffle = True, \n",
    "                                   random_state = None)\n",
    "test_dataset_noheaders = fetch_20newsgroups(subset = 'test',\n",
    "                                  categories=comp_categories+rec_categories, \n",
    "                                  remove=('headers', 'footers'), #toggle head/foot\n",
    "                                  shuffle = True, \n",
    "                                  random_state = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_noheaders = train_dataset_noheaders.target > 3\n",
    "y_test_noheaders = test_dataset_noheaders.target > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.7835269271383316, total= 1.4min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.7875264270613108, total= 1.4min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.795142555438226, total= 1.4min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.750791974656811, total= 1.4min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.8317460317460318, total= 1.4min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.7888067581837381, total= 1.4min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.7793030623020063, total= 1.4min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.7888067581837381, total= 1.4min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.8616684266103485, total=   2.0s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.8521647307286166, total=   2.1s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  5.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.8289334741288279, total=   2.2s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.8625792811839323, total=   2.5s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.8804232804232804, total=   2.4s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.8732840549102429, total=   2.0s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.8585005279831045, total=   1.9s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.8099260823653643, total=   2.0s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.8636363636363636, total=   2.2s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.8772486772486773, total=   2.0s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.8402116402116402, total= 1.5min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.806553911205074, total= 1.6min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9440337909186906, total= 2.1min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9398099260823654, total= 2.2min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9408658922914467, total= 2.2min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9281183932346723, total= 2.2min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9365079365079365, total= 2.1min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9429778247096093, total= 2.1min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9514255543822597, total= 1.8min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9461457233368532, total= 1.9min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9493136219640972, total=  42.5s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9323467230443975, total= 2.0min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9450897571277719, total=  48.6s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9481481481481482, total= 2.0min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9461457233368532, total=  40.6s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9493136219640972, total=  30.4s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9281183932346723, total= 1.0min\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9376979936642027, total=  35.9s\n",
      "[CV] classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9597883597883597, total= 1.1min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9482576557550159, total=  36.3s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9587301587301588, total=  28.4s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=GaussianNB(priors=None), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9386892177589852, total=  34.6s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9609292502639916, total= 1.6min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9736008447729673, total= 1.5min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9598732840549102, total= 1.5min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.959830866807611, total= 1.5min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9661375661375662, total= 1.5min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9630411826821542, total= 1.5min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9714889123548046, total= 1.5min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9577613516367476, total= 1.5min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9662090813093981, total=   2.1s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9757127771911299, total=   2.2s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9736008447729673, total=   2.4s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9682875264270613, total=   2.1s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9798941798941799, total=   2.6s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9683210137275607, total=   2.0s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9746568109820486, total=   2.0s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9714889123548046, total=   2.1s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9682875264270613, total=   2.1s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9767195767195768, total=   2.1s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9630021141649049, total= 1.5min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9693121693121693, total= 1.5min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9472016895459345, total= 2.1min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9609292502639916, total= 2.1min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9471458773784355, total= 2.1min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9567053854276664, total= 2.2min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 28.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9440337909186906, total= 2.0min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9619047619047619, total= 2.1min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9630411826821542, total= 1.9min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.955649419218585, total= 2.0min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9545934530095037, total=  37.4s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9630411826821542, total=  42.3s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.955649419218585, total=  33.8s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9597883597883597, total= 1.9min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.952431289640592, total= 2.0min\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9598732840549102, total=  28.5s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9503171247357294, total=  49.7s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9662090813093981, total=  37.9s\n",
      "[CV] classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9735449735449735, total= 1.1min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9535374868004224, total=  39.4s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9503171247357294, total=  43.6s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9661375661375662, total=  27.3s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9630411826821542, total= 1.5min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9736008447729673, total= 1.5min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9588173178458289, total= 1.5min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.959830866807611, total= 1.5min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9661375661375662, total= 1.5min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9630411826821542, total= 1.5min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9736008447729673, total= 1.5min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9672650475184794, total=   2.1s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9757127771911299, total=   2.2s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9598732840549102, total= 1.5min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9736008447729673, total=   2.1s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9693446088794926, total=   2.1s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.982010582010582, total=   2.3s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9714889123548046, total=   1.9s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9746568109820486, total=   2.2s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9746568109820486, total=   2.2s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9682875264270613, total=   2.0s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9756613756613757, total=   2.3s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9630021141649049, total= 1.5min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9682539682539683, total= 1.5min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9683210137275607, total=11.9min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9545934530095037, total=11.9min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9534883720930233, total= 2.7min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.955649419218585, total= 2.7min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9693121693121693, total= 2.4min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9514255543822597, total= 2.4min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9714889123548046, total= 2.1min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9577613516367476, total= 2.1min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9630411826821542, total=  40.6s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9704329461457233, total=  47.2s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9534883720930233, total= 2.2min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.964021164021164, total= 2.3min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9704329461457233, total=  38.0s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9651531151003168, total=  30.5s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9630021141649049, total= 1.0min\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9725448785638859, total=  39.3s\n",
      "[CV] classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9777777777777777, total= 1.1min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9672650475184794, total=  36.6s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9724867724867725, total=  30.1s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.959830866807611, total=  36.6s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9598732840549102, total= 1.6min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9736008447729673, total= 1.6min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9598732840549102, total= 1.5min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9619450317124736, total= 1.5min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9661375661375662, total= 1.5min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9619852164730729, total= 1.5min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9725448785638859, total= 1.5min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9662090813093981, total=   2.1s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9588173178458289, total= 1.4min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9767687434002112, total=   2.3s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9736008447729673, total=   2.4s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9704016913319239, total=   2.5s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=3, score=0.9777777777777777, total=   2.2s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9683210137275607, total=   2.4s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9757127771911299, total=   2.1s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9725448785638859, total=   2.3s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9693446088794926, total=   2.3s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=word, vector__min_df=5, score=0.9756613756613757, total=   2.2s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9651162790697675, total= 1.5min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9682539682539683, total= 1.5min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9630411826821542, total= 2.1min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9482576557550159, total= 2.1min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9567053854276664, total= 2.2min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9429175475687104, total= 2.1min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=3, score=0.9619047619047619, total= 2.1min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9461457233368532, total= 2.1min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9619852164730729, total= 1.8min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9535374868004224, total= 1.9min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9545934530095037, total=  40.6s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9630411826821542, total=  46.0s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9534883720930233, total= 2.0min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=<function rmv_nums at 0x7f916a205e18>, vector__min_df=5, score=0.9597883597883597, total= 2.0min\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9567053854276664, total=  36.4s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9598732840549102, total=  30.3s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.952431289640592, total=  58.5s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9672650475184794, total=  38.1s\n",
      "[CV] classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5 \n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=3, score=0.9746031746031746, total= 1.0min\n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9577613516367476, total=  35.7s\n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9661375661375662, total=  25.8s\n",
      "[CV]  classify=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), reduce_dim=NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), vector__analyzer=word, vector__min_df=5, score=0.9556025369978859, total=  32.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed: 78.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time is:  4713.318192720413\n"
     ]
    }
   ],
   "source": [
    "grid1 = GridSearchCV(pipeline, cv=5, n_jobs=-1, param_grid=param_grid, verbose=5, scoring='accuracy')\n",
    "start = time.time()\n",
    "grid1.fit(train_dataset_noheaders.data, y_train_noheaders)\n",
    "end = time.time()\n",
    "print(\"run time is: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarat/packages/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/sarat/packages/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/sarat/packages/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/sarat/packages/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/sarat/packages/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/sarat/packages/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/sarat/packages/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classify</th>\n",
       "      <th>param_reduce_dim</th>\n",
       "      <th>param_vector__analyzer</th>\n",
       "      <th>param_vector__min_df</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.918805</td>\n",
       "      <td>1.473694</td>\n",
       "      <td>17.130332</td>\n",
       "      <td>1.295791</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': GaussianNB(priors=None), 'reduce_...</td>\n",
       "      <td>0.795143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789730</td>\n",
       "      <td>0.025894</td>\n",
       "      <td>32</td>\n",
       "      <td>0.840159</td>\n",
       "      <td>0.816116</td>\n",
       "      <td>0.815588</td>\n",
       "      <td>0.834390</td>\n",
       "      <td>0.842355</td>\n",
       "      <td>0.829722</td>\n",
       "      <td>0.011621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.471251</td>\n",
       "      <td>3.122685</td>\n",
       "      <td>17.592586</td>\n",
       "      <td>1.903124</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': GaussianNB(priors=None), 'reduce_...</td>\n",
       "      <td>0.788807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800719</td>\n",
       "      <td>0.021607</td>\n",
       "      <td>31</td>\n",
       "      <td>0.837781</td>\n",
       "      <td>0.827477</td>\n",
       "      <td>0.833554</td>\n",
       "      <td>0.825938</td>\n",
       "      <td>0.851334</td>\n",
       "      <td>0.835216</td>\n",
       "      <td>0.009112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.974024</td>\n",
       "      <td>0.201522</td>\n",
       "      <td>0.257087</td>\n",
       "      <td>0.016740</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': GaussianNB(priors=None), 'reduce_...</td>\n",
       "      <td>0.861668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016806</td>\n",
       "      <td>29</td>\n",
       "      <td>0.878203</td>\n",
       "      <td>0.869485</td>\n",
       "      <td>0.865522</td>\n",
       "      <td>0.888537</td>\n",
       "      <td>0.885661</td>\n",
       "      <td>0.877482</td>\n",
       "      <td>0.008907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.764021</td>\n",
       "      <td>0.081319</td>\n",
       "      <td>0.258923</td>\n",
       "      <td>0.039839</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': GaussianNB(priors=None), 'reduce_...</td>\n",
       "      <td>0.873284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.856509</td>\n",
       "      <td>0.024237</td>\n",
       "      <td>30</td>\n",
       "      <td>0.885337</td>\n",
       "      <td>0.871863</td>\n",
       "      <td>0.848877</td>\n",
       "      <td>0.882462</td>\n",
       "      <td>0.879060</td>\n",
       "      <td>0.873520</td>\n",
       "      <td>0.013117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110.821222</td>\n",
       "      <td>2.699372</td>\n",
       "      <td>17.709511</td>\n",
       "      <td>1.339870</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': GaussianNB(priors=None), 'reduce_...</td>\n",
       "      <td>0.939810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937870</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>28</td>\n",
       "      <td>0.938970</td>\n",
       "      <td>0.936856</td>\n",
       "      <td>0.942404</td>\n",
       "      <td>0.938457</td>\n",
       "      <td>0.939530</td>\n",
       "      <td>0.939243</td>\n",
       "      <td>0.001815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.200926</td>\n",
       "      <td>6.565029</td>\n",
       "      <td>17.820144</td>\n",
       "      <td>1.574361</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': GaussianNB(priors=None), 'reduce_...</td>\n",
       "      <td>0.942978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944210</td>\n",
       "      <td>0.006535</td>\n",
       "      <td>27</td>\n",
       "      <td>0.940819</td>\n",
       "      <td>0.937384</td>\n",
       "      <td>0.943989</td>\n",
       "      <td>0.938457</td>\n",
       "      <td>0.943491</td>\n",
       "      <td>0.940828</td>\n",
       "      <td>0.002629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>51.425494</td>\n",
       "      <td>10.130593</td>\n",
       "      <td>0.470305</td>\n",
       "      <td>0.113862</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': GaussianNB(priors=None), 'reduce_...</td>\n",
       "      <td>0.949314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945689</td>\n",
       "      <td>0.010206</td>\n",
       "      <td>26</td>\n",
       "      <td>0.953765</td>\n",
       "      <td>0.941876</td>\n",
       "      <td>0.951651</td>\n",
       "      <td>0.944268</td>\n",
       "      <td>0.951677</td>\n",
       "      <td>0.948647</td>\n",
       "      <td>0.004678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32.641359</td>\n",
       "      <td>3.145125</td>\n",
       "      <td>0.476872</td>\n",
       "      <td>0.073507</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': GaussianNB(priors=None), 'reduce_...</td>\n",
       "      <td>0.949314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946534</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>25</td>\n",
       "      <td>0.948745</td>\n",
       "      <td>0.934742</td>\n",
       "      <td>0.949273</td>\n",
       "      <td>0.947174</td>\n",
       "      <td>0.951149</td>\n",
       "      <td>0.946217</td>\n",
       "      <td>0.005876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>72.551724</td>\n",
       "      <td>2.985955</td>\n",
       "      <td>17.448617</td>\n",
       "      <td>1.584450</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LinearSVC(C=10, class_weight=None...</td>\n",
       "      <td>0.960929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964074</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>14</td>\n",
       "      <td>0.969617</td>\n",
       "      <td>0.964861</td>\n",
       "      <td>0.970938</td>\n",
       "      <td>0.967248</td>\n",
       "      <td>0.969105</td>\n",
       "      <td>0.968354</td>\n",
       "      <td>0.002110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>71.012288</td>\n",
       "      <td>1.046832</td>\n",
       "      <td>17.652008</td>\n",
       "      <td>1.135203</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LinearSVC(C=10, class_weight=None...</td>\n",
       "      <td>0.963041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964920</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>11</td>\n",
       "      <td>0.969617</td>\n",
       "      <td>0.966711</td>\n",
       "      <td>0.970410</td>\n",
       "      <td>0.965927</td>\n",
       "      <td>0.967256</td>\n",
       "      <td>0.967984</td>\n",
       "      <td>0.001728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.011568</td>\n",
       "      <td>0.160401</td>\n",
       "      <td>0.246155</td>\n",
       "      <td>0.034914</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LinearSVC(C=10, class_weight=None...</td>\n",
       "      <td>0.966209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972739</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>4</td>\n",
       "      <td>0.978071</td>\n",
       "      <td>0.973580</td>\n",
       "      <td>0.974373</td>\n",
       "      <td>0.977021</td>\n",
       "      <td>0.976499</td>\n",
       "      <td>0.975909</td>\n",
       "      <td>0.001676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.789176</td>\n",
       "      <td>0.095145</td>\n",
       "      <td>0.282696</td>\n",
       "      <td>0.054651</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LinearSVC(C=10, class_weight=None...</td>\n",
       "      <td>0.968321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971893</td>\n",
       "      <td>0.003371</td>\n",
       "      <td>6</td>\n",
       "      <td>0.977279</td>\n",
       "      <td>0.973844</td>\n",
       "      <td>0.972787</td>\n",
       "      <td>0.975700</td>\n",
       "      <td>0.975970</td>\n",
       "      <td>0.975116</td>\n",
       "      <td>0.001599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>109.004618</td>\n",
       "      <td>2.070384</td>\n",
       "      <td>17.251323</td>\n",
       "      <td>0.958029</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LinearSVC(C=10, class_weight=None...</td>\n",
       "      <td>0.947202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954776</td>\n",
       "      <td>0.006449</td>\n",
       "      <td>23</td>\n",
       "      <td>0.961162</td>\n",
       "      <td>0.949009</td>\n",
       "      <td>0.955614</td>\n",
       "      <td>0.955098</td>\n",
       "      <td>0.958806</td>\n",
       "      <td>0.955938</td>\n",
       "      <td>0.004107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>102.114639</td>\n",
       "      <td>3.810986</td>\n",
       "      <td>17.335364</td>\n",
       "      <td>1.418743</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LinearSVC(C=10, class_weight=None...</td>\n",
       "      <td>0.944034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954987</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>21</td>\n",
       "      <td>0.960898</td>\n",
       "      <td>0.956935</td>\n",
       "      <td>0.963276</td>\n",
       "      <td>0.960644</td>\n",
       "      <td>0.959335</td>\n",
       "      <td>0.960218</td>\n",
       "      <td>0.002076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44.796953</td>\n",
       "      <td>10.360567</td>\n",
       "      <td>0.467995</td>\n",
       "      <td>0.062004</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LinearSVC(C=10, class_weight=None...</td>\n",
       "      <td>0.954593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959425</td>\n",
       "      <td>0.008157</td>\n",
       "      <td>19</td>\n",
       "      <td>0.961955</td>\n",
       "      <td>0.951651</td>\n",
       "      <td>0.959313</td>\n",
       "      <td>0.959060</td>\n",
       "      <td>0.961711</td>\n",
       "      <td>0.958738</td>\n",
       "      <td>0.003738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>34.842966</td>\n",
       "      <td>6.342053</td>\n",
       "      <td>0.489609</td>\n",
       "      <td>0.128758</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LinearSVC(C=10, class_weight=None...</td>\n",
       "      <td>0.959873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959214</td>\n",
       "      <td>0.006460</td>\n",
       "      <td>20</td>\n",
       "      <td>0.968296</td>\n",
       "      <td>0.959841</td>\n",
       "      <td>0.962483</td>\n",
       "      <td>0.960909</td>\n",
       "      <td>0.963295</td>\n",
       "      <td>0.962965</td>\n",
       "      <td>0.002924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>71.099370</td>\n",
       "      <td>1.779972</td>\n",
       "      <td>17.530347</td>\n",
       "      <td>1.053287</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LogisticRegression(C=10, class_we...</td>\n",
       "      <td>0.963041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>12</td>\n",
       "      <td>0.970145</td>\n",
       "      <td>0.965390</td>\n",
       "      <td>0.972787</td>\n",
       "      <td>0.966984</td>\n",
       "      <td>0.969369</td>\n",
       "      <td>0.968935</td>\n",
       "      <td>0.002564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>70.462849</td>\n",
       "      <td>1.404007</td>\n",
       "      <td>17.117170</td>\n",
       "      <td>1.213680</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LogisticRegression(C=10, class_we...</td>\n",
       "      <td>0.963041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965554</td>\n",
       "      <td>0.004841</td>\n",
       "      <td>9</td>\n",
       "      <td>0.969089</td>\n",
       "      <td>0.966711</td>\n",
       "      <td>0.970410</td>\n",
       "      <td>0.967512</td>\n",
       "      <td>0.968841</td>\n",
       "      <td>0.968512</td>\n",
       "      <td>0.001287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.893744</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.258057</td>\n",
       "      <td>0.043030</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LogisticRegression(C=10, class_we...</td>\n",
       "      <td>0.967265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973584</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977279</td>\n",
       "      <td>0.974373</td>\n",
       "      <td>0.978071</td>\n",
       "      <td>0.977813</td>\n",
       "      <td>0.978083</td>\n",
       "      <td>0.977124</td>\n",
       "      <td>0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.863421</td>\n",
       "      <td>0.090751</td>\n",
       "      <td>0.254048</td>\n",
       "      <td>0.032745</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LogisticRegression(C=10, class_we...</td>\n",
       "      <td>0.971489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972950</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>2</td>\n",
       "      <td>0.977807</td>\n",
       "      <td>0.975958</td>\n",
       "      <td>0.975958</td>\n",
       "      <td>0.976228</td>\n",
       "      <td>0.978083</td>\n",
       "      <td>0.976807</td>\n",
       "      <td>0.000939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>357.387376</td>\n",
       "      <td>271.167187</td>\n",
       "      <td>21.629581</td>\n",
       "      <td>2.708611</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LogisticRegression(C=10, class_we...</td>\n",
       "      <td>0.954593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960270</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>16</td>\n",
       "      <td>0.965390</td>\n",
       "      <td>0.959313</td>\n",
       "      <td>0.963804</td>\n",
       "      <td>0.960644</td>\n",
       "      <td>0.964352</td>\n",
       "      <td>0.962701</td>\n",
       "      <td>0.002319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>113.898107</td>\n",
       "      <td>7.769509</td>\n",
       "      <td>19.951610</td>\n",
       "      <td>1.893279</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LogisticRegression(C=10, class_we...</td>\n",
       "      <td>0.951426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959637</td>\n",
       "      <td>0.007328</td>\n",
       "      <td>18</td>\n",
       "      <td>0.967503</td>\n",
       "      <td>0.960634</td>\n",
       "      <td>0.964333</td>\n",
       "      <td>0.962758</td>\n",
       "      <td>0.963560</td>\n",
       "      <td>0.963757</td>\n",
       "      <td>0.002243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>49.985741</td>\n",
       "      <td>10.826823</td>\n",
       "      <td>0.471471</td>\n",
       "      <td>0.104524</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LogisticRegression(C=10, class_we...</td>\n",
       "      <td>0.963041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968935</td>\n",
       "      <td>0.005523</td>\n",
       "      <td>7</td>\n",
       "      <td>0.973316</td>\n",
       "      <td>0.965654</td>\n",
       "      <td>0.971731</td>\n",
       "      <td>0.968568</td>\n",
       "      <td>0.973594</td>\n",
       "      <td>0.970572</td>\n",
       "      <td>0.003040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>34.155782</td>\n",
       "      <td>3.663280</td>\n",
       "      <td>0.452898</td>\n",
       "      <td>0.040638</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LogisticRegression(C=10, class_we...</td>\n",
       "      <td>0.965153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967456</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>8</td>\n",
       "      <td>0.972523</td>\n",
       "      <td>0.968032</td>\n",
       "      <td>0.968824</td>\n",
       "      <td>0.970681</td>\n",
       "      <td>0.971217</td>\n",
       "      <td>0.970256</td>\n",
       "      <td>0.001627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>72.621574</td>\n",
       "      <td>2.121691</td>\n",
       "      <td>18.553060</td>\n",
       "      <td>1.211796</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LogisticRegression(C=100, class_w...</td>\n",
       "      <td>0.959873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>12</td>\n",
       "      <td>0.969881</td>\n",
       "      <td>0.964861</td>\n",
       "      <td>0.970410</td>\n",
       "      <td>0.967248</td>\n",
       "      <td>0.969105</td>\n",
       "      <td>0.968301</td>\n",
       "      <td>0.002026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>70.494015</td>\n",
       "      <td>1.411696</td>\n",
       "      <td>17.274579</td>\n",
       "      <td>1.250977</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LogisticRegression(C=100, class_w...</td>\n",
       "      <td>0.961985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965342</td>\n",
       "      <td>0.004781</td>\n",
       "      <td>10</td>\n",
       "      <td>0.969881</td>\n",
       "      <td>0.966975</td>\n",
       "      <td>0.969881</td>\n",
       "      <td>0.966719</td>\n",
       "      <td>0.970161</td>\n",
       "      <td>0.968724</td>\n",
       "      <td>0.001538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.052499</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.239810</td>\n",
       "      <td>0.015060</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LogisticRegression(C=100, class_w...</td>\n",
       "      <td>0.966209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972950</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>2</td>\n",
       "      <td>0.978336</td>\n",
       "      <td>0.973316</td>\n",
       "      <td>0.975165</td>\n",
       "      <td>0.976492</td>\n",
       "      <td>0.979139</td>\n",
       "      <td>0.976490</td>\n",
       "      <td>0.002110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.019682</td>\n",
       "      <td>0.126238</td>\n",
       "      <td>0.254239</td>\n",
       "      <td>0.032130</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LogisticRegression(C=100, class_w...</td>\n",
       "      <td>0.968321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972316</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>5</td>\n",
       "      <td>0.977807</td>\n",
       "      <td>0.974901</td>\n",
       "      <td>0.973844</td>\n",
       "      <td>0.975964</td>\n",
       "      <td>0.978611</td>\n",
       "      <td>0.976225</td>\n",
       "      <td>0.001771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>110.095354</td>\n",
       "      <td>2.479221</td>\n",
       "      <td>17.508457</td>\n",
       "      <td>1.342072</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LogisticRegression(C=100, class_w...</td>\n",
       "      <td>0.948258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954565</td>\n",
       "      <td>0.007819</td>\n",
       "      <td>24</td>\n",
       "      <td>0.960898</td>\n",
       "      <td>0.949538</td>\n",
       "      <td>0.955614</td>\n",
       "      <td>0.955890</td>\n",
       "      <td>0.960391</td>\n",
       "      <td>0.956466</td>\n",
       "      <td>0.004101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>99.608699</td>\n",
       "      <td>5.573179</td>\n",
       "      <td>17.386816</td>\n",
       "      <td>1.169682</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>&lt;function rmv_nums at 0x7f916a205e18&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LogisticRegression(C=100, class_w...</td>\n",
       "      <td>0.946146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954987</td>\n",
       "      <td>0.005560</td>\n",
       "      <td>21</td>\n",
       "      <td>0.961427</td>\n",
       "      <td>0.957464</td>\n",
       "      <td>0.963276</td>\n",
       "      <td>0.961173</td>\n",
       "      <td>0.959863</td>\n",
       "      <td>0.960640</td>\n",
       "      <td>0.001926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>48.263349</td>\n",
       "      <td>10.011301</td>\n",
       "      <td>0.516689</td>\n",
       "      <td>0.101452</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classify': LogisticRegression(C=100, class_w...</td>\n",
       "      <td>0.954593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960270</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>16</td>\n",
       "      <td>0.962748</td>\n",
       "      <td>0.951387</td>\n",
       "      <td>0.958785</td>\n",
       "      <td>0.960380</td>\n",
       "      <td>0.963295</td>\n",
       "      <td>0.959319</td>\n",
       "      <td>0.004287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32.123016</td>\n",
       "      <td>4.178502</td>\n",
       "      <td>0.385629</td>\n",
       "      <td>0.118096</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classify': LogisticRegression(C=100, class_w...</td>\n",
       "      <td>0.959873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961327</td>\n",
       "      <td>0.004604</td>\n",
       "      <td>15</td>\n",
       "      <td>0.967768</td>\n",
       "      <td>0.960898</td>\n",
       "      <td>0.962748</td>\n",
       "      <td>0.961701</td>\n",
       "      <td>0.963560</td>\n",
       "      <td>0.963335</td>\n",
       "      <td>0.002394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       68.918805      1.473694        17.130332        1.295791   \n",
       "1       71.471251      3.122685        17.592586        1.903124   \n",
       "2        1.974024      0.201522         0.257087        0.016740   \n",
       "3        1.764021      0.081319         0.258923        0.039839   \n",
       "4      110.821222      2.699372        17.709511        1.339870   \n",
       "5      100.200926      6.565029        17.820144        1.574361   \n",
       "6       51.425494     10.130593         0.470305        0.113862   \n",
       "7       32.641359      3.145125         0.476872        0.073507   \n",
       "8       72.551724      2.985955        17.448617        1.584450   \n",
       "9       71.012288      1.046832        17.652008        1.135203   \n",
       "10       2.011568      0.160401         0.246155        0.034914   \n",
       "11       1.789176      0.095145         0.282696        0.054651   \n",
       "12     109.004618      2.070384        17.251323        0.958029   \n",
       "13     102.114639      3.810986        17.335364        1.418743   \n",
       "14      44.796953     10.360567         0.467995        0.062004   \n",
       "15      34.842966      6.342053         0.489609        0.128758   \n",
       "16      71.099370      1.779972        17.530347        1.053287   \n",
       "17      70.462849      1.404007        17.117170        1.213680   \n",
       "18       1.893744      0.042254         0.258057        0.043030   \n",
       "19       1.863421      0.090751         0.254048        0.032745   \n",
       "20     357.387376    271.167187        21.629581        2.708611   \n",
       "21     113.898107      7.769509        19.951610        1.893279   \n",
       "22      49.985741     10.826823         0.471471        0.104524   \n",
       "23      34.155782      3.663280         0.452898        0.040638   \n",
       "24      72.621574      2.121691        18.553060        1.211796   \n",
       "25      70.494015      1.411696        17.274579        1.250977   \n",
       "26       2.052499      0.135900         0.239810        0.015060   \n",
       "27       2.019682      0.126238         0.254239        0.032130   \n",
       "28     110.095354      2.479221        17.508457        1.342072   \n",
       "29      99.608699      5.573179        17.386816        1.169682   \n",
       "30      48.263349     10.011301         0.516689        0.101452   \n",
       "31      32.123016      4.178502         0.385629        0.118096   \n",
       "\n",
       "                                       param_classify  \\\n",
       "0                             GaussianNB(priors=None)   \n",
       "1                             GaussianNB(priors=None)   \n",
       "2                             GaussianNB(priors=None)   \n",
       "3                             GaussianNB(priors=None)   \n",
       "4                             GaussianNB(priors=None)   \n",
       "5                             GaussianNB(priors=None)   \n",
       "6                             GaussianNB(priors=None)   \n",
       "7                             GaussianNB(priors=None)   \n",
       "8   LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "9   LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "10  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "11  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "12  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "13  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "14  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "15  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "16  LogisticRegression(C=10, class_weight=None, du...   \n",
       "17  LogisticRegression(C=10, class_weight=None, du...   \n",
       "18  LogisticRegression(C=10, class_weight=None, du...   \n",
       "19  LogisticRegression(C=10, class_weight=None, du...   \n",
       "20  LogisticRegression(C=10, class_weight=None, du...   \n",
       "21  LogisticRegression(C=10, class_weight=None, du...   \n",
       "22  LogisticRegression(C=10, class_weight=None, du...   \n",
       "23  LogisticRegression(C=10, class_weight=None, du...   \n",
       "24  LogisticRegression(C=100, class_weight=None, d...   \n",
       "25  LogisticRegression(C=100, class_weight=None, d...   \n",
       "26  LogisticRegression(C=100, class_weight=None, d...   \n",
       "27  LogisticRegression(C=100, class_weight=None, d...   \n",
       "28  LogisticRegression(C=100, class_weight=None, d...   \n",
       "29  LogisticRegression(C=100, class_weight=None, d...   \n",
       "30  LogisticRegression(C=100, class_weight=None, d...   \n",
       "31  LogisticRegression(C=100, class_weight=None, d...   \n",
       "\n",
       "                                     param_reduce_dim  \\\n",
       "0   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "1   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "2   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "3   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "4   NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "5   NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "6   NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "7   NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "8   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "9   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "10  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "11  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "12  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "13  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "14  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "15  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "16  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "17  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "18  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "19  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "20  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "21  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "22  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "23  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "24  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "25  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "26  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "27  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "28  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "29  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "30  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "31  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "\n",
       "                   param_vector__analyzer param_vector__min_df  \\\n",
       "0   <function rmv_nums at 0x7f916a205e18>                    3   \n",
       "1   <function rmv_nums at 0x7f916a205e18>                    5   \n",
       "2                                    word                    3   \n",
       "3                                    word                    5   \n",
       "4   <function rmv_nums at 0x7f916a205e18>                    3   \n",
       "5   <function rmv_nums at 0x7f916a205e18>                    5   \n",
       "6                                    word                    3   \n",
       "7                                    word                    5   \n",
       "8   <function rmv_nums at 0x7f916a205e18>                    3   \n",
       "9   <function rmv_nums at 0x7f916a205e18>                    5   \n",
       "10                                   word                    3   \n",
       "11                                   word                    5   \n",
       "12  <function rmv_nums at 0x7f916a205e18>                    3   \n",
       "13  <function rmv_nums at 0x7f916a205e18>                    5   \n",
       "14                                   word                    3   \n",
       "15                                   word                    5   \n",
       "16  <function rmv_nums at 0x7f916a205e18>                    3   \n",
       "17  <function rmv_nums at 0x7f916a205e18>                    5   \n",
       "18                                   word                    3   \n",
       "19                                   word                    5   \n",
       "20  <function rmv_nums at 0x7f916a205e18>                    3   \n",
       "21  <function rmv_nums at 0x7f916a205e18>                    5   \n",
       "22                                   word                    3   \n",
       "23                                   word                    5   \n",
       "24  <function rmv_nums at 0x7f916a205e18>                    3   \n",
       "25  <function rmv_nums at 0x7f916a205e18>                    5   \n",
       "26                                   word                    3   \n",
       "27                                   word                    5   \n",
       "28  <function rmv_nums at 0x7f916a205e18>                    3   \n",
       "29  <function rmv_nums at 0x7f916a205e18>                    5   \n",
       "30                                   word                    3   \n",
       "31                                   word                    5   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'classify': GaussianNB(priors=None), 'reduce_...           0.795143   \n",
       "1   {'classify': GaussianNB(priors=None), 'reduce_...           0.788807   \n",
       "2   {'classify': GaussianNB(priors=None), 'reduce_...           0.861668   \n",
       "3   {'classify': GaussianNB(priors=None), 'reduce_...           0.873284   \n",
       "4   {'classify': GaussianNB(priors=None), 'reduce_...           0.939810   \n",
       "5   {'classify': GaussianNB(priors=None), 'reduce_...           0.942978   \n",
       "6   {'classify': GaussianNB(priors=None), 'reduce_...           0.949314   \n",
       "7   {'classify': GaussianNB(priors=None), 'reduce_...           0.949314   \n",
       "8   {'classify': LinearSVC(C=10, class_weight=None...           0.960929   \n",
       "9   {'classify': LinearSVC(C=10, class_weight=None...           0.963041   \n",
       "10  {'classify': LinearSVC(C=10, class_weight=None...           0.966209   \n",
       "11  {'classify': LinearSVC(C=10, class_weight=None...           0.968321   \n",
       "12  {'classify': LinearSVC(C=10, class_weight=None...           0.947202   \n",
       "13  {'classify': LinearSVC(C=10, class_weight=None...           0.944034   \n",
       "14  {'classify': LinearSVC(C=10, class_weight=None...           0.954593   \n",
       "15  {'classify': LinearSVC(C=10, class_weight=None...           0.959873   \n",
       "16  {'classify': LogisticRegression(C=10, class_we...           0.963041   \n",
       "17  {'classify': LogisticRegression(C=10, class_we...           0.963041   \n",
       "18  {'classify': LogisticRegression(C=10, class_we...           0.967265   \n",
       "19  {'classify': LogisticRegression(C=10, class_we...           0.971489   \n",
       "20  {'classify': LogisticRegression(C=10, class_we...           0.954593   \n",
       "21  {'classify': LogisticRegression(C=10, class_we...           0.951426   \n",
       "22  {'classify': LogisticRegression(C=10, class_we...           0.963041   \n",
       "23  {'classify': LogisticRegression(C=10, class_we...           0.965153   \n",
       "24  {'classify': LogisticRegression(C=100, class_w...           0.959873   \n",
       "25  {'classify': LogisticRegression(C=100, class_w...           0.961985   \n",
       "26  {'classify': LogisticRegression(C=100, class_w...           0.966209   \n",
       "27  {'classify': LogisticRegression(C=100, class_w...           0.968321   \n",
       "28  {'classify': LogisticRegression(C=100, class_w...           0.948258   \n",
       "29  {'classify': LogisticRegression(C=100, class_w...           0.946146   \n",
       "30  {'classify': LogisticRegression(C=100, class_w...           0.954593   \n",
       "31  {'classify': LogisticRegression(C=100, class_w...           0.959873   \n",
       "\n",
       "         ...         mean_test_score  std_test_score  rank_test_score  \\\n",
       "0        ...                0.789730        0.025894               32   \n",
       "1        ...                0.800719        0.021607               31   \n",
       "2        ...                0.857143        0.016806               29   \n",
       "3        ...                0.856509        0.024237               30   \n",
       "4        ...                0.937870        0.005435               28   \n",
       "5        ...                0.944210        0.006535               27   \n",
       "6        ...                0.945689        0.010206               26   \n",
       "7        ...                0.946534        0.007731               25   \n",
       "8        ...                0.964074        0.005303               14   \n",
       "9        ...                0.964920        0.004918               11   \n",
       "10       ...                0.972739        0.004964                4   \n",
       "11       ...                0.971893        0.003371                6   \n",
       "12       ...                0.954776        0.006449               23   \n",
       "13       ...                0.954987        0.006557               21   \n",
       "14       ...                0.959425        0.008157               19   \n",
       "15       ...                0.959214        0.006460               20   \n",
       "16       ...                0.964286        0.005321               12   \n",
       "17       ...                0.965554        0.004841                9   \n",
       "18       ...                0.973584        0.005164                1   \n",
       "19       ...                0.972950        0.002722                2   \n",
       "20       ...                0.960270        0.007015               16   \n",
       "21       ...                0.959637        0.007328               18   \n",
       "22       ...                0.968935        0.005523                7   \n",
       "23       ...                0.967456        0.004788                8   \n",
       "24       ...                0.964286        0.005190               12   \n",
       "25       ...                0.965342        0.004781               10   \n",
       "26       ...                0.972950        0.004249                2   \n",
       "27       ...                0.972316        0.003084                5   \n",
       "28       ...                0.954565        0.007819               24   \n",
       "29       ...                0.954987        0.005560               21   \n",
       "30       ...                0.960270        0.007990               16   \n",
       "31       ...                0.961327        0.004604               15   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0             0.840159            0.816116            0.815588   \n",
       "1             0.837781            0.827477            0.833554   \n",
       "2             0.878203            0.869485            0.865522   \n",
       "3             0.885337            0.871863            0.848877   \n",
       "4             0.938970            0.936856            0.942404   \n",
       "5             0.940819            0.937384            0.943989   \n",
       "6             0.953765            0.941876            0.951651   \n",
       "7             0.948745            0.934742            0.949273   \n",
       "8             0.969617            0.964861            0.970938   \n",
       "9             0.969617            0.966711            0.970410   \n",
       "10            0.978071            0.973580            0.974373   \n",
       "11            0.977279            0.973844            0.972787   \n",
       "12            0.961162            0.949009            0.955614   \n",
       "13            0.960898            0.956935            0.963276   \n",
       "14            0.961955            0.951651            0.959313   \n",
       "15            0.968296            0.959841            0.962483   \n",
       "16            0.970145            0.965390            0.972787   \n",
       "17            0.969089            0.966711            0.970410   \n",
       "18            0.977279            0.974373            0.978071   \n",
       "19            0.977807            0.975958            0.975958   \n",
       "20            0.965390            0.959313            0.963804   \n",
       "21            0.967503            0.960634            0.964333   \n",
       "22            0.973316            0.965654            0.971731   \n",
       "23            0.972523            0.968032            0.968824   \n",
       "24            0.969881            0.964861            0.970410   \n",
       "25            0.969881            0.966975            0.969881   \n",
       "26            0.978336            0.973316            0.975165   \n",
       "27            0.977807            0.974901            0.973844   \n",
       "28            0.960898            0.949538            0.955614   \n",
       "29            0.961427            0.957464            0.963276   \n",
       "30            0.962748            0.951387            0.958785   \n",
       "31            0.967768            0.960898            0.962748   \n",
       "\n",
       "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0             0.834390            0.842355          0.829722         0.011621  \n",
       "1             0.825938            0.851334          0.835216         0.009112  \n",
       "2             0.888537            0.885661          0.877482         0.008907  \n",
       "3             0.882462            0.879060          0.873520         0.013117  \n",
       "4             0.938457            0.939530          0.939243         0.001815  \n",
       "5             0.938457            0.943491          0.940828         0.002629  \n",
       "6             0.944268            0.951677          0.948647         0.004678  \n",
       "7             0.947174            0.951149          0.946217         0.005876  \n",
       "8             0.967248            0.969105          0.968354         0.002110  \n",
       "9             0.965927            0.967256          0.967984         0.001728  \n",
       "10            0.977021            0.976499          0.975909         0.001676  \n",
       "11            0.975700            0.975970          0.975116         0.001599  \n",
       "12            0.955098            0.958806          0.955938         0.004107  \n",
       "13            0.960644            0.959335          0.960218         0.002076  \n",
       "14            0.959060            0.961711          0.958738         0.003738  \n",
       "15            0.960909            0.963295          0.962965         0.002924  \n",
       "16            0.966984            0.969369          0.968935         0.002564  \n",
       "17            0.967512            0.968841          0.968512         0.001287  \n",
       "18            0.977813            0.978083          0.977124         0.001406  \n",
       "19            0.976228            0.978083          0.976807         0.000939  \n",
       "20            0.960644            0.964352          0.962701         0.002319  \n",
       "21            0.962758            0.963560          0.963757         0.002243  \n",
       "22            0.968568            0.973594          0.970572         0.003040  \n",
       "23            0.970681            0.971217          0.970256         0.001627  \n",
       "24            0.967248            0.969105          0.968301         0.002026  \n",
       "25            0.966719            0.970161          0.968724         0.001538  \n",
       "26            0.976492            0.979139          0.976490         0.002110  \n",
       "27            0.975964            0.978611          0.976225         0.001771  \n",
       "28            0.955890            0.960391          0.956466         0.004101  \n",
       "29            0.961173            0.959863          0.960640         0.001926  \n",
       "30            0.960380            0.963295          0.959319         0.004287  \n",
       "31            0.961701            0.963560          0.963335         0.002394  \n",
       "\n",
       "[32 rows x 24 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(grid1.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results the best combination are:\n",
    "\n",
    "#### Headers and Footers Present:\n",
    "\n",
    "|Rank|Avg Test Accuracy|Test Accuracy Std|Classifier used|Features used|min_df|Default Analyzer?|\n",
    "|:--:|-------------------------------------------------:\n",
    "|1|97.506|0.004565|Logistic Reg. with  C=10 L1 Reg|LSA|5|No|\n",
    "|1|97.506|0.004566|Linear SVC with C=10|LSA|3|No|\n",
    "|1|97.506|0.004759|Logistic Reg. with  C=100 L2 Reg|LSA|3|No| \n",
    "\n",
    "#### Removing Headers and Footers\n",
    "\n",
    "|Rank|Avg Test Accuracy|Test Accuracy Std|Classifier used|Features used|min_df|Default Analyzer?|\n",
    "|:--:|-------------------------------------------------:\n",
    "|1|97.3584|0.00516|Linear SVC with C=10|LSA|3|Yes|\n",
    "|2|97.295|0.002722|Logistic Reg. with  C=100 L2 Reg|LSA|3|Yes| \n",
    "|2|97.295|0.004249|Logistic Reg. with  C=10 L1 Reg|LSA|5|Yes|\n",
    "\n",
    "### Over all the best results are observed when we do not remove the headers and Footers.\n",
    "### The best result is with Logistic Reg with C=10 and L1 Regularization. (Taking std into account)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_q8 = ['comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
    "                 'misc.forsale', 'soc.religion.christian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_q8 = fetch_20newsgroups(subset = 'train', categories = categories_q8,\n",
    "                                   shuffle = True, random_state = None)\n",
    "test_dataset_q8 = fetch_20newsgroups(subset = 'test', categories = categories_q8,\n",
    "                                  shuffle = True, random_state = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2352, 8699)\n",
      "(1565, 8699)\n"
     ]
    }
   ],
   "source": [
    "X_train_q8_counts = vectorizer.fit_transform(train_dataset_q8.data)\n",
    "print(X_train_q8_counts.shape)\n",
    "X_test_q8_counts = vectorizer.transform(test_dataset_q8.data)\n",
    "print(X_test_q8_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_q8_tfidf = tfidf_transformer.fit_transform(X_train_q8_counts)\n",
    "X_test_q8_tfidf = tfidf_transformer.transform(X_test_q8_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimentionality Reduction, LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2352, 50)\n",
      "(1565, 50)\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "X_train_q8_lsa = svd.fit_transform(X_train_q8_tfidf)\n",
    "X_test_q8_lsa = svd.transform(X_test_q8_tfidf)\n",
    "print(X_train_q8_lsa.shape)\n",
    "print(X_test_q8_lsa.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_multiclass_nb = GaussianNB()\n",
    "clf_multiclass_nb.fit(X_train_q8_lsa,train_dataset_q8.target)\n",
    "y_pred_q8_nb = clf_multiclass_nb.predict(X_test_q8_lsa)\n",
    "scores_prob_q8_nb = np.argmax(clf_multiclass_nb.predict_proba(X_test_q8_lsa), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_q8_nb = confusion_matrix(test_dataset_q8.target, y_pred_q8_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix_4(confusion_q8_nb, title='Naive Bayes confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_q8_nb = accuracy_score(test_dataset_q8.target, y_pred_q8_nb)\n",
    "recall_q8_nb = recall_score(test_dataset_q8.target, y_pred_q8_nb, average='weighted')\n",
    "precision_q8_nb = precision_score(test_dataset_q8.target, y_pred_q8_nb, average='weighted')\n",
    "f1_score_q8_nb = f1_score(test_dataset_q8.target, y_pred_q8_nb, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of (Gaussian) Naive Bayes:   0.7246006389776358\n",
      "Recall of (Gaussian) Naive Bayes:     0.7246006389776358\n",
      "Precision of (Gaussian) Naive Bayes:  0.7231391622931213\n",
      "F1 score of (Gaussian) Naive Bayes:   0.708882976103418\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of (Gaussian) Naive Bayes:  ', accuracy_q8_nb)\n",
    "print('Recall of (Gaussian) Naive Bayes:    ', recall_q8_nb)\n",
    "print('Precision of (Gaussian) Naive Bayes: ', precision_q8_nb)\n",
    "print('F1 score of (Gaussian) Naive Bayes:  ', f1_score_q8_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi class SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One vs Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_multiclass_1vsR = OneVsRestClassifier(LinearSVC(random_state=42))\n",
    "clf_multiclass_1vsR.fit(X_train_q8_lsa, train_dataset_q8.target)\n",
    "y_pred_q8_multiclass_1vsR = clf_multiclass_1vsR.predict(X_test_q8_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_q8_multiclass_1vsR = confusion_matrix(test_dataset_q8.target, y_pred_q8_multiclass_1vsR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEYCAYAAACnYrZxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXeYVEXWh9/fzJBWogISFHERRHAVARUFQRFzdhVFBRHjml1cddU1u2JeddX9TCjIYlgjiBIFBSVnFAUFBQUEVCQLw/n+qGpohu6enpnbMD3U+zz36dt1656qm86te6rqHJkZgUAgEChb5OzoCgQCgUAgeoJyDwQCgTJIUO6BQCBQBgnKPRAIBMogQbkHAoFAGSQo90AgECiDBOUeyBiS/iJpiaRVknYrgZxVkv4YZd12FJJmSTqytJQnaaSkS7ZXfbIFSXdJetWvN/D3YG7EZRwh6asoZcZTZpW7pO6SZkhaI2mxpGclVd/R9UqGpCMlbfI30UpJX0m6KCK5C6OoYxHLLQc8BhxrZpXNbHlxZfn9v42udtEj6WVJ9xWWz8yam9nI7VClbcqLV1iZZkfdd5nAzL7392B+SeRIMkn7xMn91Mz2LXkNE1MmlbuknsCDwN+AakAbYC9gqKTyO7JuhfCjmVUGqgI3AM9LytjFzzC7AxWBWTu6IqUBSXk7ug5lFTnKpC4rEWZWphacYlwFdC6QXhn4Cejh/98FvAH0AVbilFDruPz1gLeApcA84Nok5bUBFgO5cWlnANP9+iHAROA3YAnwWBI5RwILC6T9BJwd978pMBT4Gfgq/hiBE4Ev/LH8ANwI7AKsBTb5c7IKqJeg7ErAo8B3wApgNFDJbzvVn5tfgZHAfnH7zfflTPf7vY5T6E2A1YD5MkcADf3/vLj9RwKX+PV9gFFezjLg9bh8Buzj16v5a7bU1/d2IMdv6+7r/gjwi79uJ6S4V+bjGgDTfX1fxL2UPvTncRhQIy7/m/5arwA+AZr79MuADcDv/ngHxMm/2ctfD+T5tE5++yDg0Tj5rwMvpXGPHwXMiPs/DBgf9380cHpcHToBx/v6bfB1nBZ3De4FxvhjHgLUjJOV6vpvvi7+/8vAfaR/370MPA184MseBzSK2344MMGf7wnA4QXunft9vdfi7p+RvvzPYtcB2A3oh3v+JgAN42Q8ASzw2yYBR8Rtuwt41a839MeaBxwWd0yrgHXA/Lhn/XN/rhYB/wbK+22feBmr/X7nUOCZB/bzx/CrP+enpnuuEt4nO0IBZ3LxN/FG4pRI3LZXgP5xF28dTinmAg8AY/22HH+x7wDKA38EvgWOS1LmN8AxBZTALX79c6CrX68MtEkiY/OF9uWfins4DvJpu/gb8SJ/k7XEKcGYglkUuzmBGkDLgnJTnLOn/U1V35+Lw4EKbFHSxwDlgJuAuXE37HxgPO5FuCvwJXBFwQci0f+4BzSm3PsDt/ljrwi0S6REcIr9PaCKl/k1cLHf1h2nvC71x/EX4EdASY57PjAWp9Dr416mk4GD/PGPAO6My9/Dl1sB+BcwtcDDd18C+VOBPdnyspzPFuVex5fZETgfd49VSeMer4hTaDX9vbDYH2cV3It6LbBbgvLuwiusAtfgG3+tK/n/vfy2wq5/QuVehPvuZVxD5RB/HP2A1/y2XXEv6K5+Wxf/f7e4en8PNPfby/m0uUAjXCPgC39/dPJ5+gC948q/AKf884Ce/jxWLHiuSHDv+vRYmQ/4/61wjb08v8+XwPWJ7uMEz3w5X/dbcTqnI06J71vYuUq2lMVPmZrAMjPbmGDbIr89xmgzG2TOltYXONCnHwzUMrN7zOx3c/be54Fzk5TZH3fzIakK7oXR32/bAOwjqaaZrTKzsSnqXk/Sr7iH8x3gr2Y2xW87GddC6G1mG81sMu7L4qy4cppJqmpmv/jtheI/Z3sA15nZD2aWb2afmdl6XOviAzMbamYbcC3iSjjlH+NJM/vRzH7GtZRapFNuAjbgTGf1zGydmY1OUNdcX6e/m9lKM5uP++LoGpftOzN73l/TV4C6OOWdjKfMbImZ/QB8Cowzsyn++N/BKXoAzOwlX+563MN/oKRqhRzXk2a2wMzWFtxgZouBK3w9nwC6mdnKQuRhZutwX4Ptgda4L4PRQFuccpljRevj6G1mX/s6vsGWa5jO9S8pb5vZeP+89osr+yTccfT193t/YDZwSty+L5vZLL99Q9yxfGNmK3BfYN+Y2TAv/022vp6vmtlyv/+juJd2UcygT+Jefrd5eZPMbKyXNx/4P6BDmrLa4Bp/vbzOGQEMxOsVT7JzlZCyqNyXATWT2Djr+u0xFsetrwEq+v32wiva2IJ7oyZTEv8FzpRUATgTmGxm3/ltF+NaQLMlTZB0coq6/2hm1XGmpSdxb+8YewGHFqjT+bjWH8CfcS+V7ySNknRYinLiqYlrCX6TYFs9nOkDADPbhPt6qB+Xp+A5rJxmuQW5CRAw3o/w6JGkruXj6+TXE9bHzNb41VR1WhK3vjbB/8rgXiySekn6RtJvuBZxrE6pWFDI9oG4r4yvEr3QUjAK1/Jr79dH4hRJB/+/KCS7hulc/5KSVtmegtc60blN63qC65uT9KWkFf55qkbh1zO27+W483+ePy9IaiJpoB/A8Rvwz3Tl4Y53QUyWJ+m9TRrPWllU7p/j7JtnxidK2gU4ARiehowFwDwzqx63VDGzExNlNrMvcBfiBOA8nLKPbZtjZl2A2rhO3v/5uiTFtwxvBv4k6fS4Oo0qUKfKZvYXv88EMzvNl/MurgUG7lMwFctw5qlGCbb9iHupAK7jCmdi+KEQmYlY7X//EJcWezFhZovN7FIzqwdcDjwTP7Igrq6xFn6MBsWsT1E5DzgN94lfDffZDe6FBMnPc2Hn/37c53tdSV0KyRtPQeU+isKVe1FdwBZ2/deQ5HoWo6yUZXsKXutilyHpCNwz1hnXr1IdZ9tXyh237HsvcJr/QojxLO7rorGZVcU1CAuV5/kR2LNAx3CJ7u0yp9z9yb4beErS8ZLKSWqI+yRbiDO/FMZ44DdJN0uq5Ftt+0s6OMU+/wWuxT1sb8YSJV0gqZZ/I//qkwsdUmVmv+NMDnf4pIFAE0ld/TGVk3SwpP0klZd0vqRq/vP0t7gylgC7JTMf+Hq9BDwmqZ4/1sP8V8gbwEmSjvZDG3viXpyfFVb/BOUsxd2oF/gyehD3QpF0tqQ9/N9fcA9ufgEZ+b5O90uqImkv4K/A9hjeVwV37MtxCu2fBbYvwfXNpI2k9rg+lG5+eUpSfb+toR861zDJ7p/hTAiH4DpTZ+G/7nCdd4lYAjQswsiSwq7/VOA8fz2PZ2sTRMr7Lg0G4e738yTlSToHaIZ7DqKgCq5vbimQJ+kO3BdzSiTtiev47mZmXyeQ+RuwSlJTXJ9PPKnukXG4BtBN/tk+EmeCei29w9mWMqfcAczsIdxb8xHcyR6Ha/ke7VvFhe2fjzuxLXAjLpYBL+BabMnoj2tJjTCzeNPP8cAsSatwdtVzvc00HV4CGkg6xdtij8XZ/X/EfaI9iLMTgrM7z/efg1fgOosws9m+bt96c069BOXcCMzAjSb42cvNMbOvvJyn/Dk4BTjFv3iKw6W40SnLcR1h8S+Jg4Fx/jy9j+sDmJdAxjW4h+BbnJ35v7jzlGn64L7OfsB11BXsO3kR1+fxq6R3CxMmqaqXebXv6xjtZfSOayHHytsGM1uN6/ydFXc9Psf1OfyUpNhYo2O5pEL7ZNK4/tf5tJiJ8N24fdO571KVvRzXz9QTd7/cBJxc4NkqCYNxNvmvced5HYWb0ACOxn2h/E9uTsoqSbHhvjfivvBW4vroXi+w713AK/58dI7f4M/pqbiv/2XAM7gXyOxiHBvgRxEEAoHShaTbgaVm9n87ui6B7CQo90AgECiDlEmzTCAQCOzsBOUeCAQCZZCg3AOBQKAMEpwZBUoNORWrWm6VWhmT37RecUflFU5ubrrDmYtHjjIrf8rkScvMrFgnP7fqXmYbt56Aa2uXDjaz4yOpXKBYBOUeKDXkVqnFbqc/mDH5b9+XcA5aJOxWObPORiuVj9SV+Db8oXxOwdmgaWMb11Gh6daeOdZNeSrdmZmBDBGUeyAQKBkCcoMqKW2EKxIIBEqGBLnldnQtAgUIyj0QCJQQQU5mzUaBohOUe6BUUiEvh3dvOpLyeTnk5YqBk37g4fe/oMdRjbi0U2P2rl2ZZje8z8+r3Ez4Mw/dk6uPd95aV6/L5+Z+k/li4YpURWzFUa33Y5fKlcnJzSUvN4+3hzgHjX1eeJZ+vf+P3Nw8jux0HDfdcX+Rj+WHhQu48tKLWLJkCTk5OVx40cVcftW1/PLzz1x84Xks+P479mywFy/16U/1GjWKLL8g+fn5tG1zMPXq1+ftdweUWF6hSMEsUwoJVyRQKlm/cRN/fnQUa9bnk5cr3r/pKIbPXMz4ucsZOn0Rb9+4tZvs75et4YyHR7FizQY67l+HR7q24sQHRhSpzD5vfciuu23pBxw7ehTDBw9kwIhxlK9QgeVLk7lsSU1uXh73PPAQB7ZoycqVKzn6iEPp0LETr/XrQ/sjO3J9z5v416MP8a/HHuKuex8oVhnxPP3UEzRtuh+/rfytxLLSQ5AXzDKljTDOPVBqWbPeOYUsl+ta72Ywc8GvLFi+Zpu8E79Zzoo1Ll7DpG+XU7dGpRKX3/+VF7jsmp6Ur+B8s+1Wq3ax5NSpU5cDW7QEoEqVKjTetymLFv3IoA8GcO75Ls7Iued3ZdDA90tc54ULF/LRh4Po3uPiEstKG+HMMvFLquxSRUnjJU3zvvvv9ukvS5onaapfWvh0SXpS0lxJ0yW1zPxBZT9BuQdKLTmCYXd0Yuajp/DJlz8xZd7Pae13Xru9GTFzceEZ45BEj3NP5Yxj2/JaX+dkct63c5g49jPOOqED559+HNOnTCryMRTk++/mM2PaVFq1PoSlPy2hTp26gHsBLCvml0E8N/W8gfseeJCcnO35aPsO1fglNeuBjmZ2IM7z6vGS2vhtfzOzFn6Z6tNOABr75TKc3/RAIQSzTCFIegEX1PoLSavMrLiRhqKs03xcMO9I3J9KehkYaGb/i0JeVGwy6HTPMKpWKkfvKw+jab2qzP4xtamh7b616NKuIac9OLJIZfUfMJzd69Rl+dKf6H7OKTTapwn5Gzfy24pfeXPQSKZPmcT1l3Vl+PhZqJgTilatWkX38ztz/4OPUrVqoa7Di8ygDwZSq3YtWrZsxSejRkYuPylFtLmb81a4yv8t55dUHgxPA/r4/cZKqi6prpktKm6VdwZCy70QzOwSH2mpTKDE4QdLdRm/rd3AZ18v5aj966TMt1/9ajzarRXdn/6MX1YXzeX87r4FvVut2hxzwqlMnzKROvXqc+yJpyKJA1u2Rjk5/LK8eO/TDRs20P38zpx1ThdOOe0MAGrV3p3Fi51+Wrx4ETWLafaJMfazMXwwcABNG+9Ntwu6MOrjEfS4sGvhO5YYJTLL1JQ0MW65bKs9XICPqbgA4UPNbJzfdL83vTzuA8aACzUX72t9IdGG+iuTZFS5S+rmL9Q0SX0l7SVpuE8bLqmBz/eypGclfSzpW0kdJL0kF9/w5Th5qyQ9Kmmy33+b6dJ+35jNboqP2NNX0mlxefpJOlVSc2/7m+rr1DiBvJGSWsf936Z8n+dxSZ/4Oh8s6W1JcyTdl+TczJf0oC9/vHxIOUm7S3rHn7NpkpIFI77G12OGj/qCpEMkfeaP+zNJ+/r07pLelDQAGOJtmP+W9IWkD3Ch+WL7v+3XT5O0Vi7KU0VJ3/r0S+ViwU6T9JakP8Rdw8ckfQw8KGkXfw0n+PqcluAYkrJb5fJUreQ+7yuWy+GI/XZn7uLksaPr71qJl648jKtfmsC3S1YlzZeINatXs2rVys3rY0YNp3HTZnQ6/hTGjnYR6+Z9M4cNG36nxm5Fn3hpZlx75aU02bcpV15zw+b0E048mdf6ucBgr/Xry4knnZJMRFrcc/8DzJ23gNlz5tHn1f50OKojL72STuCxEqKEZpllZtY6bnkufhdzgdhbAHsAh0jaH/g70BQXuGVXXBg8SByqLvgqL4SMteIkNcdFBW9rZssk7YqL8t7HzF6RC7P2JBCLEVoDFxD6VGAALpL7JcAESTH72y644NM95cJi3QlcXaDoG4GrzGyMpMq4CCsvADcA78mF/TocuBB4HHjCzPpJKo8LVJyKVOX/bmbtJV0HvAe0wkU1+kbS45Y4Gv1vZnaIpG7Av3CRZ57ExUo9Q1IuyYPgLjOzlpKu9Md8CS5+Y3sz2yipEy4U3J99/sOAA8zsZ0ln4kK0/QkX9PsLXDSjyWyJDn8EMBP3oOXholmBi8D+PIB/cV2Mi9QDLhB4JzPLl/RPXFSqHpKq4wJfD/MRhDbjW3SXAeRU3qI4a1erxJM9WpObI3Ik3p+4kKHTF3Fxx3246vgm1K5akRF3HsPwGYvp2WcSfz25GTV2KU+v81318/M3cdz96Y2WWbbsJ666yE2fz9+YzylndqZ9x2P5/fffufWGKzipQ2vKlS/Pg08+VyyTzLjPx/BG/340a74/HQ5rBcDtd93HdX+9iR7dutCvT2/q77EnvfsWO6LajqUEk5jM7FdJI4HjzewRn7xeUm/cfQ2upb5n3G574KKRBVKQyU/0jsD/YnZhr1QOY0vg6r7AQ3H5B5iZSZoBLDGzGQByIawa4uI1bmJL6KpXgbcTlDsGFw+0H04RLQRGSXpaUm1f/lteAX4O3CYXu/NtM5tTyDGlKj821GEGLvTZIl//b3E3ZiLl3j/u93G/3hEXTzMW7i/ZYO1Y2ZPYck6r4cJ4Nca1bOKfuKFmFuuRbA/09/J/lDTCl7dRbkTCfrjYnI/5vLnAp37f/b1Sr4578QyOK+NNLxNcSMBTJcUe0Iq4gL9fxh+Eb9E9B1CuVqPNrbEvf1jBMfduG8v8xRFzeXHE3G3Se/aZRM8+xevwbLDX3gwYMW6b9PLly/PI0yWP4Nfm8HYsX7Uh4bZ3PxhSYvmJaN/hSNp3ODIjsgviBsukP4nJf/Fu8Iq9Ei7o+IPydnS5N+jpuMYFuGfrakmv4WLErgj29sLJpFlGFP7pFL89Ftt0U9x67H+yl9A28s2sF64VWwnX+dLUb+qLi/N4EdDb5/0v7kthLTBYUsdC6pvJ+hf1MzNWRn6c/HuBj81sf1xsy4px+bdqMaco71Pc6IQNwDCgnV9iQZdfxsX9/BMuEHmyMgT8OW7kQwMz20qxB8oIEsrZeimEusDHkqbj4vYONbOBQD/fuJsB1ARiJs1BuJi5c3GxSa/MxGGUNTKp3IcDnSXtBuDNMp/hAjyDU7SjiygzBzjLr5+XaH9Jjcxshpk9CEzE2fDAKaXrAXykeCT9EfjWzJ7EtQ4OKGn5ReScuN/P/fpwfNR0uU6nogyrqMaWgMrdU+T7BDjXy68LHFVg2/XA52a2FNgNdw5jQYCrAIsklcNdw2QMxvULyB/LQSnyBrKc3NzcrZZUmNl0MzvIzA4ws/3N7B6f3tHM/uTTLjCzVT7dzOwqM2vkt0/cDoeU9WRMuXsFej/OJDIN94l/LXCRf2N3xUVPLwqrgeaSJuHMF/cASLpC0hU+z/WSZvoy1+IinGNmS3Amgd5x8s4BZsr12jfFRaNH0iAljtaesPx0SSC3gqRxuPMQ62m7DjjKt2AmAc0LqVM8DwEPSBpD6v6Dd4A5uBbSs8CouG3jcHb4WEt9OjDdtgTb/YfPMxRn40/GvTiz0HRJM/3/QBlEEjm5OVstgR1PVgXIVgnGmftRHTOAlmaWvtORDKGIx6qXBcrVamSZ9Of+afDnnpQ/lM+ZZGatC8+5LXm7/dGqnbS1z52f+55XbHmBaNgpXrF+5Mhs4KnSoNgDgbJEaLmXTrJqhmpxW+1mNgw3UqPUYGYNd3QdAoFIEEVS6JIq4sx+FXA66H9mdqekvYHXcGPcJwNdzex3uclMfXDDi5cD55jZ/GgPouwRXrGBQKBECBWpQ5XkvmUeBB43s8bAL7g5FPjfX8xsH9yQ4czZ7soQQbkHAoGSIYo0FNKPfknkW6YjEPNv9ApbJjie5v/jtx8dG4UVSE5Q7oFAoMQksLkXybcM8A3wq5lt9Fni/cds9i3jt6/ADdENpCCrbO6BQKD0ISmRKWZZqtEyfiZzC++a4h1gv0TZYkWk2BZIQlDugVLDfvWrM/DBkjnPSkWrG9/NmOzZT/658EwloLRbIdKYlZqQON8ybYDqkvJ86zzef0zMt8xCOY+j1XB+mwIpSGqWkVQ11bI9KxkIBEovEuTm5my1pM6vWr7FTpxvmS+Bj9kyA/xCnAM+cLPHL/TrZ+Ec0oWWeyGkarnPwn36xL+SY/+NUja0MBAI7ChUqEIvQF2cg7tcXAPzDTMbKOkL4DXvmG4K8KLP/yLQV9JcXIv93ERCA1uTVLmb2Z7JtgUCgUAM13JP3yxjZtPZ4lo6Pv1bnDfSgunrgLNLUsedkbRet5LOlXSrX99DUqvMVisQCGQNXrnHL4EdT6EdqpL+jRuH2h4X/GEN8B9cEIdAYLuRn5/PyUcfTp269ejd/x3+du3lzJg6GTNj70aNefTfz7NL5fQmMVfIy+H9WzpSvlwueTliwMQFPPTeLC7uuA+XH9OEvXevwr7XvsPPq1y4vquO35ez2uwFQG5ODk3qVaHpde/xaxrh/H5YuIArL7uIn5YsIScnh24XXczlV17LA/feyYcfvE9OTg41a9Xmqf+8SN26hfmGS86CBQu45KJuLFmymJycHHpcfBlXX1tU33xFR0U3ywS2A+mMljncR/yZApuDbmTWS1IgkICX/u/f7NNkX1atdCHx7rjvYar4QNP33H4Tr7zwLFde/7e0ZK3fuIkzHx7J6vUbycsVA/9+NMNnLGb83GUMmfYj7968tWv/pz/6iqc/+gqAYw+sxxXHNklLsQPk5uVxzz8f4sAWLVm5ciVHH3EoR3bsxNXX9eTv/7gbgOeefYpHet3Ho088k5bMROTl5dHroUc5qKUr5/BDW3F0p2PYr1mzYstMh1iHaqB0kc4V2SApBz+u1Ptn35TRWgUCBVj0w0JGDPmQcy+4aHNaTLGbGevXri3ycMHV6918mXK5OZTLzcEwZnz/KwuWr0m535mHNuDtcd+nXU6dOnU5sEVLV+cqVWiyb1MW/fjj5voDrFm9psTDHevWrctBLbeU07Tpfvz44w+F7BUNOTnaakmFpD3l4iV/KWmWXGhKJN0l6QdtiYF8Ytw+f/dRwr6SdFyGD6dMkE7L/WngLaCWpLuBzrgIPIHAduPu2/7GrXf9c3Mg6xg3Xn0pHw8bzD77NuX2e4vmciRHYvidx7B37cq8OGIuk78tfOh0pfK5dNy/Drf0m1yksmJ8/918ZkyfSqvWrt/w/rv/wev9X6Vq1Wq8+8HQYslMxHfz5zN16hQOPuTQyGQmo6gdqsBGoKeZTZZUBZgkKXbwj8fFUvXy1Qw3QqY5UA8YJqlJXEjHQAIKbbmbWR/gduAR3DCks80sSyP5Zj+Suvt+kKjkNfTBNEotwwcPYreatfiTb/3G88i/n2f8rHns07gpA955s0hyN5lx1F1DOKDnAFruvStN61crdJ/jDqzH+LnL0jbJxLNq1Sq6X9CZ+3s9urnVftud9zJ99jzO6tyFF54rvkmmYDldOv+Zhx/9F1Wrbo8pKSrSOHczW2Rmk/36StwY9/opdjkNeM3M1pvZPFy4vW1G1QS2Jl1DWS4upubvRdgnUArxY4szKV/ejBcZE8d9xrCPPqBtiyZcc2k3Pvt0JNdd3n3z9tzcXE454yw+HFi8Gai/rd3AmK+W0nH/OoXmPb2IJpkYGzZs4KILOnNW5y6cfNoZ22z/c+dzGfjeO0WWm6icLp3/zDldzuf0M84sfIcIkBKaZVL6ltmyrxrihkXGIpRfLWm6pJck1fBpm33LeOL9zgSSUOhDKOk2oD/uc2gP4L+S/p6Jykjq5i/sNEl9Je0labhPGy6pgc/3sqRnvd3uW0kd/M3wpaSX4+StkvSopMl+/1oJyuwQZ+ObIqmKL/u0uDz9JJ0qqbmk8T7vdEmNE8ibL+mfkj73N3VLSYMlfSMfClBSZV+fyZJmFChrq3OQ5FTVk/SRpDmSHorb91lf5ixvQouv0x2SRgNnS2rl5X8OXBWXb5CkA/z6FEl3+PV7JV2SrN6+9f+lpGdwfrj3lHSsPweTJb0pqVi++AFuvuM+xs38hjFTv+ap5/tw+BFH8q//9Gb+t98AzuY+bPAgGjXeN22Zu1WpQNVK5QCoWC6XDs12Z87i31LuU6VSOQ5vUouPphTNjm1mXHfVpTTZtylXXnPD5vRv5s7ZvP7RoAE0bpJ+/ZOVc8WlF7Nv0/247oa/lkhWUUnQcl9mZq3jlucK7uPvibeA683sN1zIx0Y4N8CLgEdjWRMUGWaoFkI6NvcLgFZmtgZA0v242J4PRFkRSc2B24C2ZrZMLqD2K0AfM3tFUg/gSba4Aa2BcxF6KjAAaAtcAkyQ1MLMpgK7AJPNrKdXVHcCVxco+kbgKjMb42+2dcALuJim70mqBhyOm/78OPCEmfWTGzGUrBW8wMwOk/Q4LjB3W6Aibtbvf3wZZ5jZb5JqAmMlvQ80S3AOEtEC19pZD3wl6SkzWwDc5kcz5QLDJR3gJ4wArDOzdv5cTweuMbNRkh6Ok/sJcIRcCMCNvt4A7YBXU9QbYF/gIjO70m+7HehkZqsl3Qz8lQQxZ32L7jKA+nukP2/OzPjrVRezauVKzIz99v8T9z/8VNr7716tIv+++FDX0pR4b8L3DJ22iEs7Nebq45tSu1pFRt1zPMOmL+KGlycAcFLL+oyctYQ1vxfN1Dvu8zG80b8fzZrvz5GHuykit915H/369GbunK/JyRF77LkXjz7xdJHkFuSzMWP4b7++7L//nzi0VQsA7r7vnxx/QubCC0LMcVjROoPlAqy/BfQzs7dhc5zj2PbngYH+b8y3TIx4vzOBJKSj3L8rkC8P+DYDdemIi8iyDDYPuTwMiH1b9sUFgI4xwMxMLpD0EjObASBpFtAQmIob1fO6z/8zjuM3AAAgAElEQVQq8HaCcscAj0nqB7xtZgtxQb2fllTbl/+WmW30Ld3bJO3h885JIA+cLwxwMVsre7viSknr5HxqrAb+Kam9r2N9XFDqbc5BEvnDY+EC5aZs74X7bO3slWUebop3M1yAa2Lnwb+sqptZLCh2X+AEv/4pLoj5POAD4Bi52LMNzewr/0AmqjfAd2Y21q+38WWPkRsBUh74PNGB+BbdcwAHtGhVaGvssHYdOKxdBwDe/nBkYdmT8sXCFXS8e8g26c8Pm8PzwxJf1tfGzOe1MfOLXFabw9uxbOWGbdKPOe6EBLmLT9t27Vi7Ycc0aHOL4DhM7qZ4EfjSzB6LS69rZov83zOAWF/Q+ziLwWM4C0JjYHwU9S7LJFXuvtVpuElLsyQN9v+PBUZnoC4xnzWpiN++3v9uiluP/U92XNvIN7Nekj4ATsS1RDuZ2Wyc0jsf10vfw+f9r6RxwEnAYEmXmNmIBOUUVrfzgVq4L6INvqVckfTOQbx8gHwgTy5E2Y3AwWb2i5x5qmJcvtX+N1UZE4DWuJf3UKAmcCnuS40U9Y6XHytjqJl1SeNYAlmOBHlFG+feFugKzJDz6Q5wK9BFUgvc/TkfuBzAzGZJegP4AvdFeVUYKVM4qVrusbfmLFwrLsbYBHmjYDjwjqTHzWy5N0l8hlOuMUVb1JdKDs6L3GvAeYn2l9TIt/pn+C+Fprhg2i/jWgeLzWyWz/tH4Fsze9KvHwAkUu6FUQ34ySvIo3Atb0hwDlK03gtSFadgV0jaHdcaH1kwk3exukJSOzMbjTuvsW2/S1qAG+56L06RP+KXVPUuyFjgaUn7mNlc3/rfw8y+TvNYAlmEgLwitNz9fZdoh0Ep9rkfuL/IlduJSeU47MVk2zKBfzvfjzOJ5OO8wl0LvCTpb8BS4KJUMhKwGmguaRIuess5APIdm2b2H+B6r6jycS2DD/22JZK+BOKHYJwDXCBpA7AYb0OWNAi4xMzStQP2AwZImogzH81OcQ66SzoVaG1mdyQTaGbT5GYRz8K1vMekKP8i3HldAwwusO1T4GgzWyPpU5x989NU9U5Ql6WSugP95YIbg7PBB+VeBpFU1JZ7YDugwtwiS2qEe2M2I+4z38yaZLZqJUfSKjMr1igN39qcAbSM2bcDmeWAFq1s4IjPMiY/m4N17FIxs3F1KpXTpFSRk1JRo2EzO/rOV7dKe6tHq2LLC0RDOq/bl4HeuM+oE4A3cGaOMoukTrhW6VNBsQcCqZGcWSZ+Cex40lHufzCzwQBm9o2Z3Q4cldlqRUNxW+1mNszMGpjZv6KuUyBQ1oiZZeKXQvIn8y2zq6ShcvM3hspPYpLjSTnfMtMlbTtVObAN6Sj39X7o0jeSrpB0ClA7w/UKBAJZRFEch7HFt8x+uGGzV8n5j7kFN8y3MW5wwS0+/wm44Y+NcXMins3EMZQ10lHuNwCVcZ2bbXFD43pkslKBQCB7iI2WSdcsk8K3zGm4iYv439iExdNwkxnNz6WoLqluBg6lTFFoL42ZxXw+rMSNTQ0EAoHNFGOce9y+asgW3zK7xyYxmdkiP4kQkvuWWUQgKakmMb1Digk1ZrZ9vBIFdhpyc0TVSpkbFTLn6bMyJrvu6Zntnvl54Pb1FVMUnM19m9Z6TT9kNsZzBf3LqIBvGSX3Zx98yxSDVE9SZG5lA4FA2SZ3W8W8LNVQyES+ZYAlMRcE3uzyk08PvmWKQapJTMO3Z0UCgUB2IqBcERyHJfMtg/MhcyHQy/++F5d+taTXgEOBFXE+aAJJyOzMiEAgUOZxNvcijW1P5lumF/CGpIuB74Gz/bZBON9Pc3G+roo6U32nJCj3QCBQIgTkFSH+awrfMgBHJ8hvxMUdCKRH2l3ccT5CAoHtztWXX0LjvepyWOsDN6f1uu9umjVqwBGHtuKIQ1sx5KOkfqe2q+wK5XL59MnzGPdsVyY9dyG3dz0cgOd6HseXr1zC2Ge6MvaZrhzwxy2xY444YA/GPuPyD3m4c7GOI0Z+fj5tDm7JmaefUiI56RLrUI1fAjueQlvukg7B2ceqAQ0kHYhzknVNpisXCMTo0rUbl15xJVdcuvUX+V+uuY5rru9ZqmSv35DP8Te9yep1G8jLzWHEY+cyZMI8AG59fhTvjN7aX3y1XSrwxNWdOO22t1iwdCW1qlUq/sEATz/1BE2b7sdvK1NHloqKotrcA9uHdFruTwInA8vBeR8kS9wPBMoObdu1p8auyQJTlT7Zq9e54Bzl8tx0/FQO+s45qinvjZnDgqUrAVi6Ym2xy124cCEffTiI7j0uLraMIiM3WiZ+Cex40lHuOWb2XYG04Cg/UCp4/j/P0PaQg7j68kv49ZdfSo3snBwx9pmufP/6Xxgx5TsmfLUYgLu6t2P8s9146PIjKV/ORWlsvEcNqleuyOCHOjPm3xdwXqdmxa7zTT1v4L4HHiQnZ/u54I213OOXwI4nnTtggTfNmKRcSdcT/HJvV+SCc99SeM6UMmpJGicX+PqIqOpWoIzukrbb/Igel17BlFlf8+nYSexepw633/K3UiN70yajzZV92ef852i9bx2a7bUbd/QezYGX9Kbdtf2oUaUiPTsfDLjZnS0b1+aMf7zNqbe+xd/Pa8M+9WsUuc6DPhhIrdq1aNmyVZH3LQlS0ZW7XED7nyTNjEu7S9IP2hKw/sS4bX/3jsO+knRchg6lTJGOcv8LLrhxA2AJztHPXzJZqcDWmNn7ZtarhGKOBmab2UFm9mmhuQG5QNulltq7705ubi45OTlc2OMSJk2aUOpkr1i9nk+mLeTYg/dm8c8uEuHvG/LpM2QmrfetA8APS1cxZOJ81qzfyPLf1jJ6xsKtOlvTZexnY/hg4ACaNt6bbhd0YdTHI+hxYeY9hghRLmfrJQ1eBo5PkP64mbXwyyAA71TsXKC53+eZ0n5vlgYKVe5m9pOZnWtmNf1ybiyAc6DkSGooabakFyTNlNRPUidJY7zr00PiW8SSzvb5pkn6xKflSnpE0gzvEvWaAmW0wAUXP9G3iCpJ6uLzz5T0YFzeVZLukYsVe5ikXpK+8HIf8XlOifsKGCYX1q/gcdWS9JakCX5pG/W5W7xoyzyWge+/y37NmpcK2TWrVaLaLm5wWcXyeXRs2YCvFvxMnV132Zzn1MP34Yv5ywEY8Plc2u5fn9wcUalCHgc3rcvs75cXuc733P8Ac+ctYPacefR5tT8djurIS6/0LbKcoiJBbs7WS2GY2SdAuiEkTwNeM7P1ZjYPN979kGJXeCchndEyz5M4sPRlGanRzsk+uAkbl+GCVJ8HtANOxU3uiA8hdAdwnJn9IKm6T7sM2Bs4yMw2ysWf3YyZTZV0By5U39WS6gEPAq2AX4Ahkk43s3eBXYCZZnaHl/Mi0NTMLK680UAbn3YJcBNQcFjJE7hW2GhJDXDh/PYr7gm6+MLzGfPJKJYvX0bzffbiltvvZPSno5gxfRqSaNBgLx5/qnieYKOWXWfXXXj+xhPI9e5v3/rkKz4c9y0fPng2NatVQhLTv/mJa54cBsBXC35m6MT5TPjPhWwy4+WPZvDFd0VX7jsKZ3PfRqMX6lsmCVdL6gZMxLkF/gXnJCw+dnPMcVggBelMYhoWt14ROIOtPbQFSs48H6QbSbNwPq1N0gygYYG8Y4CX5aLBx3xydAL+Y2YbAdIIqn0wMNLMlvoy+wHtcS+RfJzPD4DfgHXAC5I+AAb69D2A173/j/LAvARldAKaxTmDqiqpinfxuhlJl+FeTuyxZ4OkFX7xlX7bpHXtHo3n6ahlz5y3jMOu2rbFfMLNbybd5/H/TeTx/01Mur2otO9wJO07HBmZvFTEIjEVIKVvmSQ8iwvMbv73UZx78eA4rBik4/L39fj/kvoCQzNWo52T9XHrm+L+b6LANTKzKyQdCpwETPUmF1G0mz2VUXSdmeX7sjb6zvSjcTbPq4GOwFPAY2b2vqQjgbsSyMkBDjOzlOP6fGvuOYCDWrYOD2wWIhI6DisyZrZks0xnMYg1JoLjsGJQnPFSewN7RV2RQHpIamRm48zsDmAZ7qYfAlwhKc/nKWzQ9jigg6SavmOqCzAqQVmVgWq+Y+t6oIXfVA34wa9fmKSMIbiXQUxWiyT5AlmPyM3ZeimWlK0DcJwBxEbSvA+cK6mCpL1xEZnGl6jKOwHp2Nx/YUurMAfXCVKiYXmBEvGwpMa4BtNwYBruIWgCTJe0AXge+Leke4CJZvZ+vADvUvXvwMdeziAze49tqQK8J6miz3eDT78LeFPSDzhb6N4J9r0WeFrSdNx99glwRfEPO1BaKapvGQBJ/YEjcbb5hcCdwJG+EWDAfOByADOb5c2QX+BC9F0V+7oMJEepZs7JGUz3ZEsrbZOl2iEQKAEHtWxtH48ZV3jGUki2B+v4Q/mcScWwkQOwT/MD7eH+g7dKO/PAusWWF4iGlGYZr8jfMbN8vwTFHggEtiFHWy+BHU86NvfxklpmvCaBQCArESJPOVstgR1PqhiqeX5oXTvgUknfAKvxIzPMLCj8QCCQbChkYAeTqkN1PNASOH071SUQCGQpOUXvUH0J5232JzPb36ftCryOm9sxH+hsZr/4vr8ncNGY1gDdzWxyZJUvo6T6fhKAmX2TaNlO9QsEAqUc4Vru8UsavMy2vmVuwU3ga4wbCRYblXcCbvhjY9yEt+JNRd7JSNVyryUpaRd9gcC2gUBgJyVmcy8KZvaJpIYFkk/DDY8EeAUYCdzs0/v4AR1jJVWXVDcEyU5NKuWeC1Qm9WzGQCAyJKiQl7nOOGUwiESmhyruekgpDnyWeIRMcXzL7B5T2H4uRm2fXp+tXZ7EfMsE5Z6CVMp9kZnds91qEggEshJBolmpxfEtk6qIgoRh2YVQqM09EAgECiOiMHtLYi4I/O9PPj34likGqZT70dutFoFAIGuRXFjB+KWYvM8WX0UXAu/FpXeTow2wItjbCyepWSYNt7GBQCAAOAVftPwJfcv0At6QdDHwPS7GAcAg3DDIubihkBdFUukyTjr+3AOBUsO6des4pmMHfl+/no0bN3L6mX/mH3feHZn8yy/pwYeDBlKrdm0mTZ1Z+A7FID8/n7ZtDqZe/fq8/e6AIu9foXwew168nvLl88jLzeWdYVO47z+D6HBwEx644QzKl8tlypcLuOLufuTnbwLg0ZvO4ri2zVmz7ncuu7MvU2cvjOx4RNFNMWbWJcmmbSwGfpTMVcWo2k5NmCccyCoqVKjAh0OGM27SVMZOnMLQIYMZP25s4TumSdcLu/PewI8ik5eIp596gqZNix2UivW/b+T4y57k0HN6cei5D3Ds4c1oc+DevHBPV7rd0pvWZ/+T7xf9zAWnHArAce2a0ahBLfY/7W6uvq8/T956blSHspmIzDKBCAnKPZBVSKJy5coAbNiwgQ0bNhTdJpCCdke0Z9ddC3OHX3wWLlzIRx8OonuPi0skZ/Xa3wEol5dLXl4u+fmbWP/7RuZ+7/ogR4ydzelHOxf6J3c4gP8OdO7Px8+YT7UqlahTs2qJyt8KuUsQvwR2PEG5B7KO/Px8Dm19EHvV352jj+7EIYccuqOrlDY39byB+x54kJyckj16OTli7Gu38P3wXowYO5sJM7+jXLlcWjZzoQrP6NSCPXavAUC92tVZuPiXzfv+sORX6tWunlBucYhFYopgtEwgQoJyjwhJIyW19uuD4oJJJ8t/j6RO26M+heSrJ+l/KbZXl3Rluvm3B7m5uYybOIU58xYwceIEZs3MjG08agZ9MJBatWvRsmWrEsvatMloc24v9jnudlrvvxfNGtWl2y29eajnmXza90ZWrl7PxnwXzyKRro3ae3dRzTKS5kuaIWlqbLKTpF0lDZU0x//WiLSSOxlBuaeJH4aV1vkysxPN7NdC8txhZsNS5ck03vPnj2Z2Vops1YHNyj2N/NuN6tWrc0T7DgwdklkbeVSM/WwMHwwcQNPGe9Ptgi6M+ngEPS7sWiKZK1at5ZOJczj28GaMmz6PThf/iyO6PsLoyXP55vulgGup71Fni56sv3t1Fi1dUaJy4xHOcVj8kiZHmVmLuMlOyXzLBIpBmVPuknaR9IGkaZJmSjpH0tGSpviWwkuSKvi8B0v6zOcdL6lKAVkNJX0p6RlgMrCnpGMlfS5psqQ3fZzRgnWYL6mmX/+HpNm+JdJf0o0+/WVJZ/n1ZPWbL+luX9YMSU2THPNNfvs0Sb3iNp3tj+trSUf4vN19vQcAQ/wxzvTbmvv8UyVN9+H8egGNfNrDBfI3lPSpr99kSYf79CP9l8P//LH3U0Rz/5cuXcqvv7r35tq1a/l4xHCa7JvwtJQ67rn/AebOW8DsOfPo82p/OhzVkZde6VtkOTVrVKZa5UoAVKxQjo6H7stX85dQq4a7FcuXy6Nn92N4/n+jAfhg1AzOO/kQAA75U0N+W7WWxct+i+io2Ox+IIJgHafhfMrgf4NH2hJQFodCHg/8aGYnAUiqhosxerSZfS2pD/AXr7BfB84xswmSqgJrE8jbF7jIzK70Cvt2oJOZrZZ0M/BXIKGbBm8W+TNwEO5cTwYmFchTEechb6v6AbG4bcvMrKU3jdwIXFJg/xNwD8GhZrZGWwfHzjOzQySdiBtHHDMDHQYcYGY/a2vnTVcAT5hZP0nlcf6FbgH2N7MWvrz4/D8Bx5jZOv8i6A/EWmEHAc1xMwnHAG2B0QnO0WU4T3/s2aBBwc3bsHjRIi69uDub8vPZtGkTZ551NieedHKh+6VLtwu68OmokSxbtoxGDffgH3fcXeLOz6ipU7Mqz9/TldycHHJyxFtDJ/PhpzP55/Wnc8IR+5OTI55/81NGTfgagI9Gz+K4ds2Z9f6drFm3gcvvejXiGiU0xRTmW8ZwjQsD/s9vS+ZbJlAMyqJynwE8IulBYCDwGzDPzL7221/BjZkdjvOfMwHAzJI1Zb4zs9hYuzZAM2CMb4iWBz5PUZd2wHtmthbAt5YLsm+S+sWU+9v+dxJwZoL9OwG9zWyNP474yWfx+zaMSx+aZJLa58BtkvYA3jazOYU0uMvhAnG3APJxQbpjjDezhQCSpvryt1Hu/qF+DqBlq9aFGoL/dMABjJ2QOVfefV7tnzHZ8bTvcCTtOxxZrH1nzvmRw7o8uE36rf96l1v/9W7CfW7o9UaxykqHmFmmAIX5lmlrZj96BT5U0uyMVXAnpcwpd9/6bYWb0fYAMCRJVpGe86HVBfYZmmICRqIySppnvf/NJ/H1SnUcyfZdnSAvZvZfSeOAk4DBki4Bvk1RtxuAJcCBOBPfugRlp6p7oIxQVFOMmf3of3+S9A5wCN63jG+1x/uWCRSDsmhzrwesMbNXgUeAw4GGkvbxWboCo4DZQD1JB/v9qkgqTAGNBdrGZEn6g6QmKfKPBk6RVNHb5k9KkGd2kvqlyxCgh6Q/+DoVe5C2pD8C35rZkzh/HgcAK4EqSXaphvv62eTrnVvcsgPZS1F9y/h+sSqxdeBYnOk0mW+ZQDEoi62pPwEPS9oEbMDZr6sBb3rlPQH4j5n9Lukc4ClJlXD29k7e9v6CmZ1YULCZLZXUHegf6/TE2eC/LpjX558g6X1gGvAdMBFYUSDPOkkXFaxfqgP0tvwrzOwSM/vIm0UmSvod54fj1sJOUhLOAS6QtAFYDNzj7fJjfCfqh8DTcfmfAd6SdDbwMUm+CAJlnyKObd8deMeb/PKA//r7eAKJfcsEioGiHu8a2BpJlc1slW9ZfwJcFuI/JqZlq9Y2ZuyEjMmPaMBOQjL9HGU6WMe6qU9PKq7/9QMPamVDRm3tAqJOtfLFlheIhrLYci9tPCepGVAReCUo9kBZI2aWCZQugnLPMGZ23o6uQyCQWYLLgdJIUO6BQKBECCihq5xABgjKPRAIlAwlHOce2MEE5R4IBEpEkklMgR1MUO6BQKDEBLNM6SMMhQyUGiQtxc0HSJeawLIMVSeTskuj/L3MrFZxCpL0kS8vnmVmdnxx5AWiISj3QNYiaWKmxlJnUnZZkB8o/YSPqUAgECiDBOUeCAQCZZCg3APZzHOFZymVssuC/EApJ9jcA4FAoAwSWu6BQCBQBgnKPRAIBMogQbkHAoFAGSQo90BgO+OjDwUCGSW4HwhkFT5qVgMz+yoDsv8A9PTyL5XUGNjXzAZGJP9w4AWgMtBA0oHA5WZ2ZYTyGxL3XJtZnyhkB7KP0HIPZA2STgGmAh/5/y18GMOo6I0L7H2Y/78QuC9C+Y8DxwHLAcxsGtA+CsGS+uJiBrcDDvZLmKG6ExNa7oFs4i7gEGAkgJlNldQwQvmNzOwcSV28/LWKODafmS0oIDI/ItGtgWYWxjYHPKHlHsgmNprZisKzFZvfvdnHACQ1wrXko2KBN52YpPKSbgS+jEj2TKBORLICZYDQcg9kEzMlnQfkenv4tcBnEcq/E2fy2VNSP6At0D1C+VcATwD1cSafIcBVEcmuCXwhaTxxLyQzOzUi+YEsI8xQDWQNvsPzNuBYnzQYuM/M1kUgW8AewBqgDS4GxVgzy6Rb3siQ1CFRupmN2t51CZQOgnIPZAWScoFeZva3DJYxycxaZUDuU3hTTyLM7NqoywwEglkmkBWYWb6kyBVvAcZKOtjMJkQsd2LE8rZBUhvgKWA/oDyQC6w2s6qZLjtQOgkt90DWIOlRoDHwJrA6lm5mb0ck/wugCS4a1GqcacbM7IAo5GcSSROBc3HnpjXQDWhsZrfu0IoFdhih5R7IJnbFjRHvGJdmQCTKHTghIjkJkVQLuBloBlSMpZtZx6Q7FQEzmysp18zygd6SouxsDmQZQbkHsgYzuyjD8r8DkFSbOOUbIf2A14GTcCNnLgSWRiR7jaTywFRJDwGLgODmYCcmmGUCWYOkisDFQHO2bvn2iEj+qcCjQD3gJ2Av4Eszax6R/Elm1krS9JipR9IoM0s40qWIsvfC1bkccANQDXjGzOaWVHYgOwmTmALZRF/cRJ3jgFG4oYsrI5R/L24Y5NdmtjdwNDAmQvkb/O8iSSdJOgh3DCXGzL4zs7Vm9puZ3W1mfw2KfecmtNwDWYOkKWZ2UKzlK6kcMDgqm7WkiWbWWtI04CAz2yRpvJkdEpH8k4FPgT1xI1uqAnebWbH940h6w8w6S5pBguGW2dAZHMgMweYeyCZiLd9fJe0PLMZ5QYyKXyVVBj4B+kn6CdgYlfA475IrgKMiEnud/z05InmBMkIwywSyieck1QD+AbwPfAE8GKH803AzVG/AuSH4BjglKuGSHpJUVVI5ScMlLZN0QUlkmtkiv3qlN81sXoBIXAkHspNglgkEPJJ6AJ+a2ZwMyZ9qZi0knQGcjnuJfGxmB0Yge7KZtSyQNj2YZXZeglkmkDVI+gYYi7Nbf2JmX0RcREPgAu9GeKIv51MzmxqR/HL+90Sgv5n9XFKPwpL+gmuhN5I0PW5TFaLtDA5kGaHlHsgaJFUADgWOwHlsbApMM7MzIi6nEnApcCNQ38xyI5L7AHAGsBbnl746MNDMDi2BzGpADeAB4Ja4TSvN7OcSVDeQ5QSbeyCbyMd1quYDm4AluLHdkSDpdkkf4lzx7oNT7pEMVZSUAwzARXlqbWYbcPb900oi18xWmNl84HZgsbe17437AqlesloHspnQcg9kDZLWADOAx4BhZrY8YvmTcaNjPsCNox8bhTvhOPmfm9lhhecsluypOJ8yDXGukN/HxX89MRPlBUo/oeUeyCa64IYpXgm8JuluSUdHJdx3SB4NjAeOAWZIGh2VfGCIpD9HHbrPs8nMNgJnAv8ysxuAuhkoJ5AlhA7VQNZgZu8B70lqinPydT1wE1ApCvl+7PwRQAdcK3gBrlM1Kv6K8/eSL2ktW7xORuGWd4OP/dqNLcM3y6XIHyjjBLNMIGuQ9BbQApiLH8kCjIvKdCLpA9yXwafABG8XzwokNcM5I/vczPpL2hs4x8x67eCqBXYQQbkHsgZJBwOTvUvbrMQ7J2vv/46Mm7UaCERKUO6BUo+kM1NtL2mwjmR+WeLkRzIRSFIv4GCc619wfQiTzOyW5HsVKjP4lgkkJCj3QKlHUm+/Whs4HBjh/x+Fa/2mVP5pyN/Lr17lf/v63/OBNWZ2T0nkx5UzHWhhZpv8/1xgSkkUsKS6ZrYo7hi2IuajPrDzEZR7IGuQNBC4NOZPRVJd4OmSKvc4+WPMrG1haSWQPx04Mja5SNKuuJdTiVrX/iUx2Mw6RVDNQBkhjJYJZBMN4xxlgZvE1CRC+btIamdmowEkHU600YweAKZI+hg3UqY98PeSCvXBw9dIqmZmK0oqL1A2CMo9kE2MlDQY6I+zL58LfByh/B642KPVvPwVPq1ESGprZmNwsV5H4uzuAm42s8Ulle9ZhxuXP5Stg4dfG5H8QJYRzDKBrMJ7VIyNNvnEzN6JSG4OcJaZvSGpKu7ZiKQVHBdebxvPjVEh6cJE6Wb2SibKC5R+gnIPZAXbw64s6RMza194ziLLHQt8ifMG+XrB7aF1HcgEwSwTyAq2k115qKQbcQo43rRRUu+KJwOdgI7ApBLKSoiktsBduKDeeWyZ/frHTJQXKP2Elnsga5D0Bi6AdUbsypLmJUiOTEFKOtDMpkUhK4Hs2bjgH5NwXjMBiNq5WiB7CMo9kDWURbuypJOjmKUqaVxJ/MIHyh5BuQcCcXjnYc2AirE0M+uTwfLuNrM7S7B/rIO2M5CLG5GzPrbdzCaXrIaBbCUo90DWIKkxbqx4QeUbldnkTuBIL38QzvPkaDM7Kwr5mcCPmU+GmVnH7VaZQKkidKgGsonewJ3A4zjXAxfhOg6j4izgQJxLgIsk7Q68EJVwSVcB/czsV/+/BtDFzJ4prkwzOyqq+gXKFiFYRyCbqGRmw3FfnN+Z2V24EShRsdb7fdnox7r/BEQ52uTSmGIHMLNfcLFaS4ykf8aH1ZNUQ9J9UcgOZCdBuQeyid14J08AABBtSURBVHV+stEcSVf7CU21I5Q/0SvI53GjTibjojJFRU58FCY/dr98RLJPSPDiCCH2dmKCzT2QNXh/7l8C1YF7gWrAQ2Y2NgNlNQSqmtn0CGU+jItx+h+ce4MrgAVm1jMC2dOBg81svf9fCZhoZs1LKjuQnQTlHgjEIak+WyYCAWBmn0QkOwe4DDehScAQ4IUogo9Iugk4FdcvYTifOO+b2UMllR3IToJyD2QNkpoAf2Nb5RuJ3V3Sg8A5wBdsmQhkZnZqFPILlLUrsEfEXwbHE/fiMLPBUckOZB9BuQeyBknTcCaNgrMwI5nSL+kr4ICYaSNqJI3Eta7zgKnAUmCUmf01E+UFdm7CUMhANrHRzJ7NoPxvgXLETQKKmGpm9pukS4DeZnant5VnBEnPmdllmZIfKN0E5R4o9XgTBsAASVcC77D1LMwSOfaS9BTOTr0GmCppeAH5UXltzPPRozoDt0UkMxX/tx3KCJRSgnIPZAOTcMo3Nozwb3HbjJKPRZ8YV877JZSVinuAwbhZrxMk/RGYk6nCojJXBbKTYHMPBMoAme5sDmQfQbkHshpJdSIMVZdI/l1+JmxJZNxkZg/FmX+2IgqzT6Y7mwPZRzDLBLKdF4GTMig/CuX4pf+dSALlHhGZ7mwOZBmh5R4IbCf8DNtbcbNUYw0rM7MDIpB9F84XTqSdzYHsJSj3QNYgqQ0wy8xW+v9VgGZmNi4i+a8A1xXw2viomfWISP5XOLv4DGBTLN3MvotAdkajSAWyj6DcA1mDpClAS/M3rZ/OP9HMWqbeM335ZnZQYWklkD/azNpFISsQKIxgcw9kE7K41oiZbZIU5T2cI6mG96gYG18fpfw7Jb0AFBxH/3ZJBUsqB/wFaO+TRgL/Z2YbSio7kJ0E5R7IJr6VdC0Q6zi8EjerNCoeBT6T9D///2zg/gjlXwQ0xc2CjZllDBcar6Q86+XGAn909WmXRCA7kIUEs0wga5BUG3iSLQE6hgHXm9lPEZbRHBflScBwM/siQtkzzOxPUckrIHuamR1YWFpg5yG03ANZg1fi52a4jFmSluJjtEpqYGbfRyR+rKRmUb4w4siX1MjMvgHws19L7Eo4kL2Elnsga/AK6wmgDc6c8fn/t3f3wXZV9RnHv89FBMKLIJ1aRF6DgEwag4ACKtAUGTu8lDchmaSWl4rQGRSdMoPVTm3VlmJpLdqOUBGwQIIKDAi1jEDkRRKURFAgAUYYOm1pAVuQlwgYnv6x14WTeJNcyN5333XyfGbO5Ox99l1r3cy9v7vO76z9W8AnbLeSmpF0BE1q5q00ywp3AJa2teGFpKXAVOARmpy7aG8p5O/S1HJ/uLS7A3Ci7TVtoB1DLME9qiFpEfCPwLxyahZwuu33tNT+PTQpnxtt7ynpd2g2sG6lsqKkHcY638ZSyNL+RsBuNMF9WVeli6MOCe5RDUl3rhrIJS2yvW9L7d9le+8S5Pcsq3F+aPvdbbTfBUkzbd8s6eixXm9jJU7UKTn3qMkCSWcB82nSMscD14+WBG7hbsynJG0G3ApcJulx4Ffr2GbXDgRuBg4f47W2VuJEhTJzj2qs5i7MUet8N6akTYFf0qQ15tBswH2Z7Z+vS7sRfUhwj1iFpC1YuWzupK/PImmsrfqeBhbbvnuixxP9S3CPqrVZ8lfSR2k21FhOc5PR6GqWSV+fRdLlwN7Ad8qpQ4Ef0dw09S3b5/Q1tuhHgntUTdL1tlsp+SvpIWA/20+20d5EknQDcIztZ8vxZsC3gaNoZu979Dm+mHgjfQ8gYl20FdiLn9Hso1qj7YEXB45fAnawvZzuNvyOSSyrZaIqpQzvdqycE1/SUvOfoqktcyfdbJDdpctp7oC9phwfDswrHxJ3cUdsTHJJy0Q1JH0OOIFmhj36g+u29gmV9EPgdn693volbbTfNUl7Ae+j+azgdtt3reVLYogluEc1ymYXv237xbVe/Prav8P2/l203RVJW9j+xeha/1XVsNInupG0TNTkXmBLmrovXVgg6RSaFSe1bFV3OXAYzV6vgzM1leNJv9InupGZe1RD0t7ANTRBfjD4HtFS+9mqLoZGgntUQ9J9wPn8ek78lt4G1TNJa9xisMUPm6MyCe5RDUm32D5wgvts7SapLkhaU0nf1j5sjvokuEc1JP0dTTrmWlZOy3Q2O23zJqmIiZTgHtVYzSw1s1NA0hTgk8D2tk+R9HZgN9vX9Ty06EmCe0QhaSrwH7ZfkHQQMB34hu2n+h3Z2km6gmbFzIdtT5O0CbDQ9oyehxY9SfmBqIakrSWdJ2mJpMWS/kHS1i12cSXNXqS7ABcCO9EsNazB1FIc7CWAUnZA/Q4p+pTgHjWZDzwBHAMcW55f0WL7L9v+FU2xrS/Z/gSwTYvtd+nFMls3vPIuJDVl1mO5iSlq8mbbnxs4/rykI1ts/yVJs4E/5NWdjTZssf0u/Tnwb8B2ki4D3ktTqiHWU5m5R00WSJolaaQ8jgOub7H9E4H9gC/YfkTSTsClLbbfCUkClgFH0wT0ecDetr/f47CiZ/lANSY9Sc/QpBsEbAqsKC9tADxre4uW+jkM+FfbL6/14klG0mLbe/U9jpg8MnOPSc/25ra3KP+O2N6wPEbaCuzFLOAhSedIekeL7U6ERZL26XsQMXlk5h6TnqTdbS9b3a32bd7EVPZPnU2TojFwETDP9jNt9dEFSfcDuwKPAs/x6haB03sdWPQmwT0mPUkXlBtzJuQmJkm/AcwFzgCWArsA59n+cpv9tEnSDmOdt/3oRI8lJocE94hC0uHAScBU4F+AS2w/Xu7+XGp7zAAaMRllKWRUreXCXh8C/t72rYMnbT8v6aSW+pgwkq6zfVjf44h+ZOYeVWuzsFfZb3S57Zcl7QrsDnzX9ktttD/RJG1j+7G+xxH9SHCPKCQtBt4PbAUsAu4Cnrc9p9eBjcPgH6ZyPAJsbPv5fkcWfclSyKiGpKmSNirPD5L0MUlbttlFCYZHA1+2fRSwR4vtd+kmYMrA8RTgxp7GEpNAgnvUpOvCXpK0HzCHV+98reVzqY1tPzt6UJ5PWcP1MeQS3KMmXRf2+jjwKeBq2/dJ2hlY005Hk8lzg/cBSNoLWN7jeKJnyblHNSTdCXwJ+DRweKn/cq/taT0PrXfl7tT5wH+VU9sAx9te3N+ook8J7lENSXsAp9JsQjGvFPY63vbZHfZ5iu0Lumq/TZI2BHajuTt1Wa2rfKIdteQTIwB2Bs4YXRFi+xGgs8BeVLHhRQnspwEHlFPfl3R+Avz6KzP3qIakS2lK8l4JXGR7ac9DmjQkfY2m9vwl5dQfACts/1F/o4o+JbhHVbos7FW27PsszUYXBm4H/tL2z9e17a5Jusf2O9d2LtYfWS0TVbH9C5qZ+3yaDw2PApZIOr2F5ucDj9PdNn5dWlG21gOgrPRZsYbrY8hl5h7V6Lqw11gbXki6y/be69LuRJA0E7gYeLic2hE40XYtSzmjZflANWrSdWGvBZJmAd8sx8fS7jZ+XdoamEYT1H8f2B94us8BRb8yc49qdF3Yq2zntykwus3eCM3GF9DUjW9z16dWSfqJ7emS3gf8FXAu8Ke239Pz0KInyblHTW4FNpa0LU0tlRNpUhGtGNjG7w3lMVLObT6ZA3sxml8/FPiq7WuAN/Y4nuhZ0jJRE5UUzMk0hb3OkfTjVjuQptOkNl753bB9VZt9dOQ/JZ0PHAz8TSmwlsnbeizBPWoyWNjr5HKutZ9hSV8HpgP38WpqxkANwf044IPA39p+StI2wJk9jyl6lOAeNem6sNe+tmsp8buSUqr4qoHjx4Bs1LEeyweqEYWkC4Fzbd/f91gi1lWCe1StzcJekg4AvgP8N/ACTV0Z257eRvsREylpmahdm4W9vk5Tk+WnvJpzj6hSZu4RhaSbbc/sexwRbUhwj2p0XdhL0j8BW9KkZl4YPV/JUsiIlSQtEzWZT3Mj0zHleA5NYa+DW2p/E5qgfsjAuVqWQkasJDP3qEbNhb0iJlruYIuaLJA0S9JIeRxHi4W9JL1N0tWSHpf0P5KulPS2ttqPmEiZuUc1ui7sJel7wOU05YQB5gJzbH9gXdqN6EOCe0Qh6W7bM9Z2LqIG+UA1qtJxYa8nJc0F5pXj2cCk32IvYiyZuUc1VlfYy3YbG3UgaXvgKzSbcBu4A/iY7X9vo/2IiZTgHtWQdH+Xhb0kXQKcYfv/yvGbaaostvLHI2IiZbVM1GShpC6rNk4fDewAtv8X2LPD/iI6k5x71OQSmgDfVWGvEUlbrTJzz+9IVCk/uFGTrgt7nQvcIenbNDn344AvdNBPROeSc49qTERhr5L2mUnzruCm1HaPWiW4RzVS2Cti/JKWiZqksFfEOGXmHhExhLIUMqqRwl4R45fgHjW5CLgWeCuwLU3u/aJeRxQxSSUtE9VIYa+I8cvMPWrypKS5kjYoj7mksFfEmDJzj2qksFfE+CW4RzVS2Cti/JKWiZqksFfEOCW4R01GJG01epDCXhGrl1+MqEkKe0WMU3LuUZUU9ooYnwT3iIghlJx7RMQQSnCPiBhCCe5RJUkrJN0t6V5J35I0ZR3aOkjSdeX5EZLOWsO1W0r649fRx2cl/cl4z69yzcWSjn0Nfe0o6d7XOsYYLgnuUavltmfYnga8CJw6+KIar/nn2/a1ts9ewyVbAq85uEdMtAT3GAa3AbuUGevSsmPTEmA7SYdIWihpSZnhbwYg6YOSlkm6HTh6tCFJJ0j6Snn+llJi+J7y2B84G5ha3jV8sVx3pqQfSfqJpL8YaOvTkh6QdCOw29q+CUkfKe3cU8oZD74bOVjSbZIelHRYuX4DSV8c6Puj6/ofGcMjwT2qJukNwO/RbJoNTRD9hu09geeAzwAH234XcBfwSUkbA/8MHA68H/it1TR/HnCL7XcC7wLuA84CflbeNZwp6RDg7cC7gRnAXpIOkLQXMIvmDtqjgX3G8e1cZXuf0t9S4OSB13YEDgQOBb5avoeTgadt71Pa/4ikncbRT6wHchNT1GoTSXeX57cBF9LUeX/U9qJyfl9gD+AHkgDeCCwEdgcesf0QgKRLgVPG6GMm8GEA2yuApwfvkC0OKY8fl+PNaIL95sDVtp8vfVw7ju9pmqTP06R+NgNuGHjtm7ZfBh6S9HD5Hg4Bpg/k499U+n5wHH3FkEtwj1otH6O2OzSz9VdOAd+zPXuV62bQ3OHaBgF/bfv8Vfo443X0cTFwpO17JJ0AHDTw2qptufR9uu3BPwJI2vE19htDKGmZGGaLgPdK2gVA0hRJuwLLgJ0kTS3XzV7N198EnFa+dgNJWwDP0MzKR90AnDSQy99W0m8CtwJHSdpE0uY0KaC12Rx4TNKGwJxVXvuQpJEy5p2BB0rfp5XrkbSrpE3H0U+sBzJzj6Fl+4kyA54naaNy+jO2H5R0CnC9pCeB24FpYzTxceACSScDK4DTbC+U9IOy1PC7Je/+DmBheefwLDDX9hJJVwB3A4/SpI7W5s+AO8v1P2XlPyIPALcAbwFOtf1LSV+jycUvUdP5E8CR4/vfiWGX8gMREUMoaZmIiCGU4B4RMYQS3CMihlCCe0TEEEpwj4gYQgnuERFDKME9ImII/T811k5L3AQn3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_confusion_matrix_4(cm, title, cmap = plt.cm.Blues):\n",
    "    ctgrs = ['comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
    "                 'misc.forsale', 'soc.religion.christian']\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title + ', without normalization')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(ctgrs))\n",
    "    plt.xticks(tick_marks, ctgrs, rotation=90)\n",
    "    plt.yticks(tick_marks, ctgrs)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_confusion_matrix_4(confusion_q8_multiclass_1vsR, title='One vs Rest confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_q8_1vsR = accuracy_score(test_dataset_q8.target, y_pred_q8_multiclass_1vsR)\n",
    "recall_q8_1vsR = recall_score(test_dataset_q8.target, y_pred_q8_multiclass_1vsR, average='macro')\n",
    "precision_q8_1vsR = precision_score(test_dataset_q8.target, y_pred_q8_multiclass_1vsR, average='macro')\n",
    "f1_score_q8_1vsR = f1_score(test_dataset_q8.target, y_pred_q8_multiclass_1vsR, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of One vs Rest SVM:   0.8785942492012779\n",
      "Recall of One vs Rest SVM:     0.878003750257878\n",
      "Precision of One vs Rest SVM:  0.8774364603846514\n",
      "F1 score of One vs Rest SVM:   0.8775268931698303\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of One vs Rest SVM:  ', accuracy_q8_1vsR)\n",
    "print('Recall of One vs Rest SVM:    ', recall_q8_1vsR)\n",
    "print('Precision of One vs Rest SVM: ', precision_q8_1vsR)\n",
    "print('F1 score of One vs Rest SVM:  ', f1_score_q8_1vsR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One vs One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_multiclass_1vs1 = OneVsOneClassifier(LinearSVC(random_state=42))\n",
    "clf_multiclass_1vs1.fit(X_train_q8_lsa, train_dataset_q8.target)\n",
    "y_pred_q8_multiclass_1vs1 = clf_multiclass_1vs1.predict(X_test_q8_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_q8_multiclass_1vs1 = confusion_matrix(test_dataset_q8.target, y_pred_q8_multiclass_1vs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix_4(confusion_q8_multiclass_1vs1, title='One vs One confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_q8_1vs1 = accuracy_score(test_dataset_q8.target, y_pred_q8_multiclass_1vs1)\n",
    "recall_q8_1vs1 = recall_score(test_dataset_q8.target, y_pred_q8_multiclass_1vs1, average='macro')\n",
    "precision_q8_1vs1 = precision_score(test_dataset_q8.target, y_pred_q8_multiclass_1vs1, average='macro')\n",
    "f1_score_q8_1vs1 = f1_score(test_dataset_q8.target, y_pred_q8_multiclass_1vs1, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of One vs One SVM:   0.8824281150159744\n",
      "Recall of One vs One SVM:     0.8818969840281757\n",
      "Precision of One vs One SVM:  0.8824033498829625\n",
      "F1 score of One vs One SVM:   0.882114049610867\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of One vs One SVM:  ', accuracy_q8_1vs1)\n",
    "print('Recall of One vs One SVM:    ', recall_q8_1vs1)\n",
    "print('Precision of One vs One SVM: ', precision_q8_1vs1)\n",
    "print('F1 score of One vs One SVM:  ', f1_score_q8_1vs1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
